{"name":"Android","slug":"Android","count":5,"postlist":[{"title":"Android 学习 抽象类","slug":"android-abstract","date":"2017-03-17T04:31:00.000Z","updated":"2019-07-03T13:51:36.846Z","comments":true,"path":"api/articles/android-abstract.json","excerpt":"","keywords":null,"cover":null,"content":"<p>【Tip】 抽象类只是一个面向对象的概念,所以可以用在诸如.net,jave EE,PY….. 【在Android中概念】</p>\n<h1 id=\"抽象类\"><a href=\"#抽象类\" class=\"headerlink\" title=\"**   抽象类**\"></a>**   抽象类**</h1><p>我们都知道在面向对象的领域一切都是对象，同时所有的对象都是通过类来描述的，但是并不是所有的类都是来描述对象的。如果一个类没有足够的信息来描述一个具体的对象，而需要其他具体的类来支撑它，那么这样的类我们称它为抽象类。比如new Animal()，我们都知道这个是产生一个动物Animal对象，但是这个Animal具体长成什么样子我们并不知道，它没有一个具体动物的概念，所以他就是一个抽象类，需要一个具体的动物，如狗、猫来对它进行特定的描述，我们才知道它长成啥样。 在面向对象领域由于抽象的概念在问题领域没有对应的具体概念，所以用以表征抽象概念的抽象类是不能实例化的。 同时，抽象类体现了数据抽象的思想，是实现多态的一种机制。它定义了一组抽象的方法，至于这组抽象方法的具体表现形式有派生类来实现。同时抽象类提供了继承的概念，它的出发点就是为了继承，否则它没有存在的任何意义。所以说定义的抽象类一定是用来继承的，同时在一个以抽象类为节点的继承关系等级链中，叶子节点一定是具体的实现类。（不知这样理解是否有错!!!高手指点….） 在使用抽象类时需要注意几点： 1、抽象类不能被实例化，实例化的工作应该交由它的子类来完成，它只需要有一个引用即可。 2、抽象方法必须由子类来进行重写。 3、只要包含一个抽象方法的抽象类，该方法必须要定义成抽象类，不管是否还包含有其他方法。 4、抽象类中可以包含具体的方法，当然也可以不包含抽象方法。 5、子类中的抽象方法不能与父类的抽象方法同名。 6、abstract不能与final并列修饰同一个类。 7、abstract 不能与private、static、final或native并列修饰同一个方法。 【实例】 定义一个抽象动物类Animal，提供抽象方法叫cry()，猫、狗都是动物类的子类，由于cry()为抽象方法，所以Cat、Dog必须要实现cry()方法。如下：</p>\n<blockquote>\n<ol>\n<li><p>_public abstract class Animal {  _</p>\n</li>\n<li><p>_    public abstract void cry();  _</p>\n</li>\n<li><p>_}  _</p>\n</li>\n<li><p>_public class Cat extends Animal{  _</p>\n</li>\n<li><p>_    @Override  _</p>\n</li>\n<li><p>_    public void cry() {  _</p>\n</li>\n<li><p>_        System.out.println(“猫叫：喵喵…”);  _</p>\n</li>\n<li><p>_    }  _</p>\n</li>\n<li><p>_}  _</p>\n</li>\n<li><p>_public class Dog extends Animal{  _</p>\n</li>\n<li><p>_    @Override  _</p>\n</li>\n<li><p>_    public void cry() {  _</p>\n</li>\n<li><p>_        System.out.println(“狗叫:汪汪…”);  _</p>\n</li>\n<li><p>_    }  _</p>\n</li>\n<li><p>_}  _</p>\n</li>\n<li><p>_public class Test {  _</p>\n</li>\n<li><p>_    public static void main(String[] args) {  _</p>\n</li>\n<li><p>_        Animal a1 = new Cat();  _</p>\n</li>\n<li><p>_        Animal a2 = new Dog();  _</p>\n</li>\n<li><p>_        a1.cry();  _</p>\n</li>\n<li><p>_        a2.cry();  _</p>\n</li>\n<li><p>_    }  _</p>\n</li>\n<li><p>_}  _</p>\n</li>\n<li><p>_——————————————————————–  _</p>\n</li>\n<li><p>_Output:  _</p>\n</li>\n<li><p>_猫叫：喵喵…  _</p>\n</li>\n<li><p>_狗叫:汪汪…  _</p>\n</li>\n</ol>\n</blockquote>\n","text":"【Tip】 抽象类只是一个面向对象的概念,所以可以用在诸如.net,jave EE,PY….. 【在Android中概念】**   抽象类**我们都知道在面向对象的领域一切都是对象，同时所有的对象都是通过类来描述的，但是并不是所有的类都是来描述对象的。如果一个类没有足够的信息来描","link":"","raw":null,"photos":[],"categories":[{"name":"Android","slug":"Android","count":5,"path":"api/categories/Android.json"}],"tags":[{"name":"Android","slug":"Android","count":5,"path":"api/tags/Android.json"}]},{"title":"Android 学习 碎片的生命周期","slug":"android-fragmenttest","date":"2017-03-21T11:52:08.000Z","updated":"2019-07-03T13:51:36.846Z","comments":true,"path":"api/articles/android-fragmenttest.json","excerpt":"","keywords":null,"cover":"http://be-sunshine.cn/wp-content/uploads/2017/03/20151112223048360.png","content":"<p><strong>【reference】</strong> <strong>《第一行代码-第二版》 GuoLin</strong> <strong>【Prior knowledge/先备知识】</strong> <strong>BaiDu or Google it…= =</strong>   <strong>【碎片的状态和回调】</strong> <strong>1.每个活动在其生命周期内可能会有四种状态.</strong> <strong>-运行状态</strong> <strong>-暂停状态</strong> <strong>-停止状态</strong> <strong>-销毁状态</strong> <strong>类似的,碎片也可能会经历这几种状态,不过会有一些细小的地方的部分区别.</strong> <strong>2.运行状态</strong> <strong>当一个碎片是可见的,并且他所关联的活动正处于运行状态时,该碎片也处于运行状态.</strong> <strong>3.暂停状态</strong> <strong>当一个活动进入暂停状态时(由于另一个未占满屏幕的活动被添加到了栈顶),与他相关联的可见碎片就会进入到暂停状态.</strong> <strong>4.停止状态</strong> <strong>当一个活动进入停止状态时,与他相关联的碎片就会进入到停止状态,或者通过调用FragmentTrasaction的remove(),replace()方法把碎片从活动移除,但如果在事务提交之前调用addToBackStack()方法,这时的碎片也会进入到停止状态。总的来说，进入停止状态的碎片对用户来说是完全不可见的,有可能会被系统回收.</strong> <strong>5.销毁状态</strong> <strong>碎片总是依附于活动而存在的,因此当活动被销毁时,与他相关联的碎片也就会进入到销毁态.</strong> <strong>或者通过调用FragmentTransaction 的remove()、replace()方法将碎片从活动中移除，</strong> <strong>但在事务提交之前并没有调用addToBackStack()方法，这时的碎片也会进入到销毁状态。</strong>   <strong>Fragment提供的附加回调方法:</strong> <strong>①onAttach() 当碎片和活动建立关联的时候调用。</strong> <strong>②onCreateView() 为碎片创建视图（加载布局）时调用。</strong> <strong>③ onActivityCreated() 确保与碎片相关联的活动一定已经创建完毕的时候调用。</strong> <strong>④onDestroyView() 当与碎片关联的视图被移除的时候调用。</strong> <strong>⑤onDetach() 当碎片和活动解除关联的时候调用。</strong>   <strong>【碎片的完整生命周期】</strong>   <img src=\"http://be-sunshine.cn/wp-content/uploads/2017/03/20151112223048360.png\" alt>   <strong>附上github源码(这一篇的project是FragmentTest):  <a href=\"https://github.com/834930269/Android_study\" target=\"_blank\" rel=\"noopener\">clone这个项目</a></strong></p>\n","text":"【reference】 《第一行代码-第二版》 GuoLin 【Prior knowledge/先备知识】 BaiDu or Google it…= =   【碎片的状态和回调】 1.每个活动在其生命周期内可能会有四种状态. -运行状态 -暂停状态 -停止状态 -销毁状态 类似的","link":"","raw":null,"photos":[],"categories":[{"name":"Android","slug":"Android","count":5,"path":"api/categories/Android.json"}],"tags":[{"name":"Android","slug":"Android","count":5,"path":"api/tags/Android.json"}]},{"title":"Android Inflater","slug":"android-inflater","date":"2017-04-09T02:16:24.000Z","updated":"2019-07-03T13:51:36.847Z","comments":true,"path":"api/articles/android-inflater.json","excerpt":"","keywords":null,"cover":"http://common.cnblogs.com/images/copycode.gif","content":"<p>在 实际开发中LayoutInflater这个类还是非常有用的，它的作用类似于findViewById()。不同点是LayoutInflater是用 来找res/layout/下的xml布局文件，并且实例化；而findViewById()是找xml布局文件下的具体widget控件(如 Button、TextView等)。 具体作用： 1、对于一个没有被载入或者想要动态载入的界面，都需要使用LayoutInflater.inflate()来载入； 2、对于一个已经载入的界面，就可以使用Activiyt.findViewById()方法来获得其中的界面元素。 LayoutInflater 是一个抽象类，在文档中如下声明：</p>\n<blockquote>\n<p>public abstract class LayoutInflater extends Object</p>\n</blockquote>\n<p><strong>获得 LayoutInflater 实例的三种方式</strong> <strong>1.</strong></p>\n<blockquote>\n<p>LayoutInflater inflater = getLayoutInflater();  //调用Activity的getLayoutInflater()</p>\n</blockquote>\n<p>2.</p>\n<blockquote>\n<p>LayoutInflater localinflater =(LayoutInflater)context.getSystemService (Context.LAYOUT_INFLATER_SERVICE);</p>\n</blockquote>\n<p>3.</p>\n<blockquote>\n<p> LayoutInflater inflater = LayoutInflater.from(context);</p>\n</blockquote>\n<p>其实，这三种方式本质是相同的，从源码中可以看出： <strong>getLayoutInflater()：</strong> Activity 的 getLayoutInflater() 方法是调用 PhoneWindow 的getLayoutInflater()方法，看一下该源代码：  </p>\n<blockquote>\n<p> public PhoneWindow(Context context) {<br>        super(context);<br>        mLayoutInflater = LayoutInflater.from(context);<br>}</p>\n</blockquote>\n<p>  可以看出它其实是调用 LayoutInflater.from(context)。 <strong>LayoutInflater.from(context)：</strong></p>\n<p><img src=\"http://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<blockquote>\n<p>public static LayoutInflater from(Context context) {<br>    LayoutInflater LayoutInflater =<br>            (LayoutInflater) context.getSystemService(Context.LAYOUT_INFLATER_SERVICE);<br>    if (LayoutInflater == null) {<br>        throw new AssertionError(“LayoutInflater not found.”);<br>    }<br>    return LayoutInflater;<br>}</p>\n</blockquote>\n<p><img src=\"http://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p>可以看出它其实调用 context.getSystemService()。 <strong>结论：所以这三种方式最终本质是都是调用的Context.getSystemService()。</strong> <strong>inflate 方法 通过 sdk 的 api 文档，可以知道该方法有以下几种过载形式，返回值均是 View 对象，如下</strong></p>\n<blockquote>\n<p>public View inflate (int resource, ViewGroup root)<br>public View inflate (XmlPullParser parser, ViewGroup root)<br>public View inflate (XmlPullParser parser, ViewGroup root, boolean attachToRoot)<br>public View inflate (int resource, ViewGroup root, boolean attachToRoot)</p>\n</blockquote>\n<p>示意代码：  </p>\n<blockquote>\n<p>LayoutInflater inflater = (LayoutInflater)getSystemService(LAYOUT_INFLATER_SERVICE);<br>View view = inflater.inflate(R.layout.custom, (ViewGroup)findViewById(R.id.test));<br>//EditText editText = (EditText)findViewById(R.id.content);// error<br>EditText editText = (EditText)view.findViewById(R.id.content);</p>\n</blockquote>\n<p>  <strong>对于上面代码，指定了第二个参数 ViewGroup root，当然你也可以设置为 null 值。</strong> <strong>注意：</strong></p>\n<ul>\n<li>·inflate 方法与 findViewById 方法不同；</li>\n<li>·inflater 是用来找 res/layout 下的 xml 布局文件，并且实例化；</li>\n<li>·findViewById() 是找具体 xml 布局文件中的具体 widget 控件(如:Button、TextView 等)。</li>\n</ul>\n<p>############## <a href=\"http://blog.sina.com.cn/s/blog_48a45b950100u8ax.html\" target=\"_blank\" rel=\"noopener\">http://blog.sina.com.cn/s/blog_48a45b950100u8ax.html</a></p>\n","text":"在 实际开发中LayoutInflater这个类还是非常有用的，它的作用类似于findViewById()。不同点是LayoutInflater是用 来找res/layout/下的xml布局文件，并且实例化；而findViewById()是找xml布局文件下的具体widget控件","link":"","raw":null,"photos":[],"categories":[{"name":"Android","slug":"Android","count":5,"path":"api/categories/Android.json"}],"tags":[{"name":"Android","slug":"Android","count":5,"path":"api/tags/Android.json"}]},{"title":"【第二行代码】Android学习笔记","slug":"android-study","date":"2017-03-01T10:57:37.000Z","updated":"2019-07-03T13:51:36.846Z","comments":true,"path":"api/articles/android-study.json","excerpt":"","keywords":null,"cover":null,"content":"<p>【2017/3/1】 1.[Solve] 第二行代码依赖库是v7:24 而Update后的的版本是v7:25 P122 RecyclerView在24.2.1中 但 在 25.0.1中.</p>\n","text":"【2017/3/1】 1.[Solve] 第二行代码依赖库是v7:24 而Update后的的版本是v7:25 P122 RecyclerView在24.2.1中 但 在 25.0.1中.","link":"","raw":null,"photos":[],"categories":[{"name":"Android","slug":"Android","count":5,"path":"api/categories/Android.json"}],"tags":[{"name":"Android","slug":"Android","count":5,"path":"api/tags/Android.json"}]},{"title":"聊天室内核从0开始 - 1 前置知识与NLP","slug":"type-2","date":"2019-01-01T13:02:42.000Z","updated":"2019-07-03T13:51:36.863Z","comments":true,"path":"api/articles/type-2.json","excerpt":"","keywords":null,"cover":"http://be-sunshine.cn/wp-content/uploads/2019/01/1234352-13d969531284a9f9.png","content":"<blockquote>\n<p>最后更新于2019/1/6</p>\n</blockquote>\n<h1 id=\"前置知识\"><a href=\"#前置知识\" class=\"headerlink\" title=\"前置知识\"></a>前置知识</h1><h2 id=\"TensorFlow\"><a href=\"#TensorFlow\" class=\"headerlink\" title=\"TensorFlow\"></a>TensorFlow</h2><blockquote>\n<ol>\n<li>张量(Tensor)</li>\n<li>图(Flow-&gt;Graph)</li>\n<li>会话(Session)</li>\n</ol>\n</blockquote>\n<h3 id=\"张量-Tensor\"><a href=\"#张量-Tensor\" class=\"headerlink\" title=\"张量(Tensor)\"></a>张量(Tensor)</h3><blockquote>\n<p>类似于矩阵,一维的张量叫做向量</p>\n</blockquote>\n<h3 id=\"计算图-Graph\"><a href=\"#计算图-Graph\" class=\"headerlink\" title=\"计算图(Graph)\"></a>计算图(Graph)</h3><blockquote>\n<p>TensorFlow的计算图的组成和数据结构中的图不同.</p>\n<blockquote>\n<ol>\n<li>图的节点: op-&gt;即操作.</li>\n<li>图的边: 即数据流,此处的数据流就是上述张量.</li>\n</ol>\n</blockquote>\n</blockquote>\n<h3 id=\"会话-Session\"><a href=\"#会话-Session\" class=\"headerlink\" title=\"会话(Session)\"></a>会话(Session)</h3><blockquote>\n<p>在TensorFlow中,要想启动一个图的前提是要先创建一个会话,Ts所有对图的操作,都必须在会话中进行.</p>\n</blockquote>\n<h3 id=\"模型训练一般流程\"><a href=\"#模型训练一般流程\" class=\"headerlink\" title=\"模型训练一般流程\"></a>模型训练一般流程</h3><p>document.write(“graph TD\\nA(开始) –&gt; B(定义数据集)\\nB –&gt; C(定义模型)\\nC –&gt;D(编写并训练模型)\\nD –&gt;E(模型测试)\\n”);</p>\n<h2 id=\"Android\"><a href=\"#Android\" class=\"headerlink\" title=\"Android\"></a>Android</h2><h3 id=\"模拟机替代AVG\"><a href=\"#模拟机替代AVG\" class=\"headerlink\" title=\"模拟机替代AVG\"></a>模拟机替代AVG</h3><p>为了解决Android Studio使用AVG虚拟机时会导致内存占用过大的问题. 这里我们选用网易旗下的MuMu模拟器.</p>\n<h4 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h4><p>document.write(“graph TD\\nA(开启MuMu模拟器) –&gt; B(进入到MuMu根目录的上层目录)\\nB –&gt; C(找到vmonitorbin)\\nC –&gt;D(在cmd中进入到上述地址-先进入盘符)\\nD –&gt;E(输入adb_server.exe connect port-如7555)\\n”);</p>\n<p>注意:这个必须在Android Studio开启时连接才可以,如果出现Empty host name,多连接几次就可以了. 使用这个方法就可以有效减少内存的占用问题.</p>\n<h2 id=\"神经网络\"><a href=\"#神经网络\" class=\"headerlink\" title=\"神经网络\"></a>神经网络</h2><h3 id=\"神经网络相关学习视频\"><a href=\"#神经网络相关学习视频\" class=\"headerlink\" title=\"神经网络相关学习视频\"></a>神经网络相关学习视频</h3><p><a href=\"https://www.icourse163.org/learn/DA-1002183004?tid=1002301011#/learn/content\" target=\"_blank\" rel=\"noopener\">https://www.icourse163.org/learn/DA-1002183004?tid=1002301011#/learn/content</a> 因为其中涉及内容过多,且基础,故我在此仅讲解几个比较生疏难懂的概念,而不做展开,其基础推荐在学号高数和概率论以及线性代数这三门课程以后再进行展开(也可以不需要,但理解上会有些困难).</p>\n<h3 id=\"梯度下降\"><a href=\"#梯度下降\" class=\"headerlink\" title=\"梯度下降\"></a>梯度下降</h3><blockquote>\n<p>在了解梯度下降前你需要知道</p>\n<blockquote>\n<ol>\n<li>计算图的节点是简单的操作</li>\n<li>高数求导中的链式求导法</li>\n<li>既然它们的节点时简单的运算,那么就可以很方便地使用链式求导法则对其进行求导 &gt; 比如 Y=Z+b,Z=b+2 dY/db=dZ/db+d(b)/db</li>\n</ol>\n</blockquote>\n<p>则如下图所示 <img src=\"http://be-sunshine.cn/wp-content/uploads/2019/01/1234352-13d969531284a9f9.png\" alt> 计算图是正向传播的,而计算图中的反向计算梯度是反向计算的,即函数的上升方向. 故反向传播以后计算出来的梯度只需要取负即是梯度下降的方向了.</p>\n</blockquote>\n<p>以上基础知识熟悉以后可以看这篇文章: <a href=\"https://www.jianshu.com/p/c7e642877b0e\" title=\"深入浅出,梯度下降法及其实现\" target=\"_blank\" rel=\"noopener\">深入浅出,梯度下降法及其实现</a></p>\n<h3 id=\"向量化\"><a href=\"#向量化\" class=\"headerlink\" title=\"向量化\"></a>向量化</h3><blockquote>\n<p>这个不难理解,即计算图中数据流都是向量,大大缩短计算时间.</p>\n</blockquote>\n<h3 id=\"Python广播机制\"><a href=\"#Python广播机制\" class=\"headerlink\" title=\"Python广播机制\"></a>Python广播机制</h3><blockquote>\n<p>举几个例子吧,具体在实践中总结,或查阅相关DOC.</p>\n</blockquote>\n<pre><code>A = numpy.array([1,2,3])\nresult = A + 100\nprint(result)\n\n输出: [101 102 103]</code></pre><h3 id=\"激活函数\"><a href=\"#激活函数\" class=\"headerlink\" title=\"激活函数\"></a>激活函数</h3><blockquote>\n<p>计算图的每层节点将上一层的输出作为本层的输入,如果没有激活函数,那么最终的结果等效于F(x)=x即线性函数. 而激活函数则是在层与层间添加上一个激活函数,使之并不完全作为线性函数来传递数据(即进入什么数据,出来就一定是唯一结果) 即由激活函数判断是否输出</p>\n</blockquote>\n<h3 id=\"神经元模型-参考书籍-西瓜书\"><a href=\"#神经元模型-参考书籍-西瓜书\" class=\"headerlink\" title=\"神经元模型(参考书籍-西瓜书)\"></a>神经元模型(参考书籍-西瓜书)</h3><p><img src=\"http://be-sunshine.cn/wp-content/uploads/2019/01/20180507224752660.png\" alt></p>\n<blockquote>\n<p>在生物神经网络中,，每个神经元与其他神经元相连,当它”兴奋”时,就会向相连的神经元发送化学物质,从而改变这些神经元内的电位,如果某神经元的电位超过一个”阈值”,那么他就会被激活,即”兴奋”起来,向其他神经元发送化学物质. 现在最常用的组成神经网络的节点神经元模型是M-P神经元模型.在这个模型中,神经元接收到来自其它n个神经元传递过来的输入信号,这些输入信号通过带权重的连接进行传递,神经元接收到的总输入值将与神经元的阈值进行比较,然后通过”激活函数”处理以产生神经元的输出.</p>\n</blockquote>\n<h3 id=\"神经网络分类\"><a href=\"#神经网络分类\" class=\"headerlink\" title=\"神经网络分类\"></a>神经网络分类</h3><blockquote>\n<p>大部分在上述的视频中都有系统介绍,这里我只做总结</p>\n</blockquote>\n<h4 id=\"感知机与深层神经网络\"><a href=\"#感知机与深层神经网络\" class=\"headerlink\" title=\"感知机与深层神经网络\"></a>感知机与深层神经网络</h4><p><img src=\"http://be-sunshine.cn/wp-content/uploads/2019/01/p.png\" alt></p>\n<blockquote>\n<p>即 输入层 -&gt; 隐藏层 -&gt; 输出层</p>\n</blockquote>\n<h4 id=\"BP神经网络\"><a href=\"#BP神经网络\" class=\"headerlink\" title=\"BP神经网络\"></a>BP神经网络</h4><blockquote>\n<p>BP网络即前向传播+反向传播来更新偏置. 特点:</p>\n<blockquote>\n<p>1-可以通过逐层信息传递到最后的输出. 2-沿着一条直线计算,直到最后一层,求出计算结果. 3-包含输入层、输出层和隐藏层,其目的是实现从输入到输出的映射. 4-一般包含多层,并且层与层之间是全连接的,不存在同层和跨层连接.</p>\n</blockquote>\n</blockquote>\n<h4 id=\"循环神经网络RNN和LSTM\"><a href=\"#循环神经网络RNN和LSTM\" class=\"headerlink\" title=\"循环神经网络RNN和LSTM\"></a>循环神经网络RNN和LSTM</h4><blockquote>\n<p>这类计算图是针对于成序列的数据的.</p>\n<blockquote>\n<p>类似于造句,造音乐等.如果一个序列过长,则会导致可能在计算后面序列的时候将前面序列的影响变低.从而导致序列无法有效处理”长期依赖”的问题.</p>\n</blockquote>\n</blockquote>\n<h5 id=\"RNN\"><a href=\"#RNN\" class=\"headerlink\" title=\"RNN\"></a>RNN</h5><h6 id=\"前向传播\"><a href=\"#前向传播\" class=\"headerlink\" title=\"前向传播\"></a>前向传播</h6><blockquote>\n<p>普通的CNN模型即上述的神经网络模型,而NLP遵守的规则一般为对于一个句子的分析,每个单词的分析,如果采取上述的线性模型可能会导致语言没有一点逻辑,即 “我/爱/你” - 则针对我输出A,针对爱输出B,针对你输出C 得到结果ABC. 而RNN最大的特点在于其可记忆性.什么叫可记忆性呢?即上一个单词的结果要传递给下一层,使下一个单词运算出的结果可以结合上一个单词以及当前的单词一起得出最后的结果.</p>\n</blockquote>\n<p><img src=\"http://be-sunshine.cn/wp-content/uploads/2019/01/1042406-20170306142253375-175971779.png\" alt></p>\n<blockquote>\n<p>如上图,右侧是拆分后的RNN,x(i)代表的是第i个单词,而计算后的h(i)会传递给h(i+1),y(i)是由上一层计算出来的词向量. 数学公式表达为:</p>\n<blockquote>\n<p>h(i)=g(w*h(i-1)+w*x(i)+bh) g(激活函数)一般选为tanh/Relu y(i)=g(w*h(i)+by) g一般选择sigmod/softmax</p>\n</blockquote>\n<p>优化: 因为词向量的行是相同的,所以将列拼在一起即可.</p>\n<blockquote>\n<p>h(i)=g(w*[h(i-1),x(i)]+bh)</p>\n</blockquote>\n</blockquote>\n<h6 id=\"反向传播\"><a href=\"#反向传播\" class=\"headerlink\" title=\"反向传播\"></a>反向传播</h6><blockquote>\n<p>反向传播作用依然是：减少误差,计算lost函数. 用倒数来计算某一个节点队最终结果的影响程度.训练完后,取平均值(大概,这点我没太仔细看).</p>\n</blockquote>\n<p>一个比较通俗易懂的链接: <a href=\"https://blog.csdn.net/shaomingliang499/article/details/50587300\" title=\" 一步一步教你反向传播\" target=\"_blank\" rel=\"noopener\">一步一步教你反向传播</a></p>\n<h6 id=\"RNN的几种类型\"><a href=\"#RNN的几种类型\" class=\"headerlink\" title=\"RNN的几种类型\"></a>RNN的几种类型</h6><p><img src=\"http://be-sunshine.cn/wp-content/uploads/2019/01/20180719232051968.jpg\" alt></p>\n<h5 id=\"LSTM\"><a href=\"#LSTM\" class=\"headerlink\" title=\"LSTM\"></a>LSTM</h5><blockquote>\n<p>再清楚了RNN以后,LSTM其实就是基于RNN的一个变种.</p>\n<blockquote>\n<p>因为RNN实际应用中无法解决长效记忆的问题,所以催生出了LSTM这一模型.放一个简单的视频可以看下.</p>\n</blockquote>\n<p><a href=\"https://www.bilibili.com/video/av15998549?from=search&seid=17651800282007333668\" title=\"什么是 LSTM RNN 循环神经网络 ?\" target=\"_blank\" rel=\"noopener\">什么是 LSTM RNN 循环神经网络 ?</a></p>\n</blockquote>\n<h2 id=\"NLP\"><a href=\"#NLP\" class=\"headerlink\" title=\"NLP\"></a>NLP</h2><h3 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h3><blockquote>\n<p>自然语言处理,探索如何处理及运用自然语言,即让电脑懂人类的语言. 包含文本分析、信息检索、词性标注、问答系统等.</p>\n</blockquote>\n<ol>\n<li><p>词法分析</p>\n<blockquote>\n<p>分词技术、词性标注(名词n,形容词a,副词d,人称代词rr,动词v…)、命名实体识别、词义消歧</p>\n</blockquote>\n</li>\n<li><p>句法分析</p>\n</li>\n<li><p>语义分析</p>\n</li>\n</ol>\n<h3 id=\"分词技术\"><a href=\"#分词技术\" class=\"headerlink\" title=\"分词技术\"></a>分词技术</h3><blockquote>\n<p>中科院分词系统(nlpir): <a href=\"http://ictclas.nlpir.org/nlpir/\" title=\"语义分词系统\" target=\"_blank\" rel=\"noopener\">中科院语义分词系统</a></p>\n</blockquote>\n<h3 id=\"命名实体识别\"><a href=\"#命名实体识别\" class=\"headerlink\" title=\"命名实体识别\"></a>命名实体识别</h3><blockquote>\n<p>即分词方法. 命名实体识别（Named Entity Recognition，简称NER），又称作“专名识别”，是指识别文本中具有特定意义的实体，主要包括人名、地名、机构名、专有名词等。 一般分为两种方法</p>\n<blockquote>\n<p>基于规则和词典的方法.</p>\n</blockquote>\n</blockquote>\n<p>document.write(“graph TD\\n\\nC(基于统计的方法)\\nC –&gt;D[隐马尔可夫模型]\\nC –&gt;E[较大熵]\\nC –&gt;F[支持向量机]\\nC –&gt;G[条件随机场]\\n”);</p>\n<h3 id=\"朴素贝叶斯\"><a href=\"#朴素贝叶斯\" class=\"headerlink\" title=\"朴素贝叶斯\"></a>朴素贝叶斯</h3><p>即概率论中的贝叶斯概型.</p>\n<blockquote>\n<p>在为序列定型中的用法:</p>\n<blockquote>\n<p>如: 分次以后判断每个单词是垃圾邮件的可能性大小,再用朴素贝叶斯计算出该邮件是垃圾邮件的概率.</p>\n</blockquote>\n</blockquote>\n<h3 id=\"马尔科夫过程\"><a href=\"#马尔科夫过程\" class=\"headerlink\" title=\"马尔科夫过程\"></a>马尔科夫过程</h3><blockquote>\n<p>其实我也没搞懂意义在哪~ (1)独立随机过程为马尔可夫过程。 (2)独立增量过程为马尔可夫过程：没{X(t)，t∈[0，+∞)}为一独立增量过程，且有P(X(0)=x0)=1，x0为常数，则X(t)为马尔可夫过程。 (3)泊松过程为马尔可夫过程。 (4)维纳过程为马尔可夫过程。 (5)质点随机游动过程为马尔可夫过程。 即下一时刻的状态只依赖于上一时刻,而与上一时刻以前无关.</p>\n</blockquote>\n<h3 id=\"语料的处理方法\"><a href=\"#语料的处理方法\" class=\"headerlink\" title=\"语料的处理方法\"></a>语料的处理方法</h3><ol>\n<li>数据清洗(去掉无意义的标签,url,符号等)</li>\n<li>分词、大小写转换、添加句首句尾、词性标注.</li>\n<li>统计词频、抽取文本特征、特征选择、计算特征权重、归一化</li>\n<li>划分训练集、测试集（先分几份,然后7-3划分）</li>\n</ol>\n<h1 id=\"聊天室内核从0开始-–-2-处理语料库\"><a href=\"#聊天室内核从0开始-–-2-处理语料库\" class=\"headerlink\" title=\"聊天室内核从0开始 – 2 处理语料库\"></a>聊天室内核从0开始 – 2 处理语料库</h1><p><a href=\"http://be-sunshine.cn/index.php/2019/01/04/type-3/\" target=\"_blank\" rel=\"noopener\">http://be-sunshine.cn/index.php/2019/01/04/type-3/</a></p>\n","text":"最后更新于2019/1/6前置知识TensorFlow张量(Tensor)图(Flow-&gt;Graph)会话(Session)张量(Tensor)类似于矩阵,一维的张量叫做向量计算图(Graph)TensorFlow的计算图的组成和数据结构中的图不同.图的节点: op-&gt","link":"","raw":null,"photos":[],"categories":[{"name":"Android","slug":"Android","count":5,"path":"api/categories/Android.json"},{"name":"NLP","slug":"Android/NLP","count":1,"path":"api/categories/Android/NLP.json"},{"name":"TensorFlow","slug":"Android/NLP/TensorFlow","count":1,"path":"api/categories/Android/NLP/TensorFlow.json"},{"name":"机器学习","slug":"Android/NLP/TensorFlow/机器学习","count":1,"path":"api/categories/Android/NLP/TensorFlow/机器学习.json"},{"name":"聊天机器人内核","slug":"Android/NLP/TensorFlow/机器学习/聊天机器人内核","count":1,"path":"api/categories/Android/NLP/TensorFlow/机器学习/聊天机器人内核.json"}],"tags":[{"name":"Android","slug":"Android","count":5,"path":"api/tags/Android.json"},{"name":"机器学习","slug":"机器学习","count":4,"path":"api/tags/机器学习.json"},{"name":"聊天机器人内核","slug":"聊天机器人内核","count":3,"path":"api/tags/聊天机器人内核.json"},{"name":"NLP","slug":"NLP","count":1,"path":"api/tags/NLP.json"},{"name":"TensorFlow","slug":"TensorFlow","count":1,"path":"api/tags/TensorFlow.json"}]}]}