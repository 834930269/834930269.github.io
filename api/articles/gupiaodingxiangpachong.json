{"title":"股票数据定向爬虫","slug":"gupiaodingxiangpachong","date":"2017-09-07T12:05:07.000Z","updated":"2019-07-03T13:51:36.852Z","comments":true,"path":"api/articles/gupiaodingxiangpachong.json","photos":[],"link":"","excerpt":null,"covers":null,"content":"<p>累了…直接撩代码</p>\n<pre><code>import requests\nfrom bs4 import BeautifulSoup\nimport traceback\nimport re\n\ndef getHTMLText(url):\n    try:\n        r=requests.get(url)\n        r.raise_for_status()\n        r.encoding=r.apparent_encoding\n        return r.text\n    except:\n        return &quot;&quot;\n\ndef getStockList(lst,stockURL):\n    html=getHTMLText(stockURL)\n    soup=BeautifulSoup(html,&apos;html.parser&apos;)\n    a=soup.find_all(&apos;a&apos;)\n    for i in a:\n        try:\n            href=i.attrs[&apos;href&apos;]\n            lst.append(re.findall(r&apos;[s][hz]\\d{6}&apos;,href)[0])\n        except:\n            continue\n\ndef getStockInfo(lst,stockURL,fpath):\n    for stock in lst:\n        url=stockURL+stock+&quot;.html&quot;\n        html=getHTMLText(url)\n        try:\n            if html==&quot;&quot;:\n                continue\n            infoDict={}\n            soup=BeautifulSoup(html,&apos;html.parser&apos;)\n            stockInfo=soup.find(&apos;div&apos;,attrs={&apos;class&apos;:&apos;stock-bets&apos;})\n\n            name=stockInfo.find_all(attrs={&apos;class&apos;:&apos;bets-name&apos;})[0]\n            infoDict.update({&apos;股票名称&apos;:name.text.split()[0]})\n            keyList=stockInfo.find_all(&apos;dt&apos;)\n            valueList=stockInfo.find_all(&apos;dd&apos;)\n            for i in range(len(keyList)):\n                key=keyList[i].text\n                val=valueList[i].text\n                infoDict[key]=val\n\n            with open(fpath,&apos;a&apos;,encoding=&apos;utf-8&apos;) as f:\n                f.write(str(infoDict)+&apos;\\n&apos;)\n        except:\n            traceback.print_exc()\n            continue\n\nif __name__==&apos;__main__&apos;:\n    stock_list_url = &apos;http://quote.eastmoney.com/stocklist.html&apos;\n    stock_info_url = &apos;https://gupiao.baidu.com/stock/&apos;\n    output_file = &apos;E:\\学习相关\\廖雪峰\\python_study\\库\\第三章\\BaiduStockInfo.txt&apos;\n    slist=[]\n    getStockList(slist,stock_list_url)\n    getStockInfo(slist,stock_info_url,output_file)</code></pre><p>结果(超慢的得得得多多多多多多多,还没爬完…不过应该是解析全文默认编码的问题): 2017-09-07 20:08:30 星期四 :earth_asia:<a href=\"https://github.com/834930269/python_study/blob/master/%E5%BA%93/%E7%AC%AC%E4%B8%89%E7%AB%A0/BaiduStockInfo.txt\" title=\"github: 爬取结果.txt\" target=\"_blank\" rel=\"noopener\">github: 爬取结果.txt</a></p>\n","categories":[{"name":"Python","slug":"Python","count":41,"path":"api/categories/Python.json"},{"name":"未分类","slug":"Python/未分类","count":3,"path":"api/categories/Python/未分类.json"},{"name":"爬虫","slug":"Python/未分类/爬虫","count":2,"path":"api/categories/Python/未分类/爬虫.json"}],"tags":[{"name":"Python","slug":"Python","count":65,"path":"api/tags/Python.json"},{"name":"爬虫","slug":"爬虫","count":4,"path":"api/tags/爬虫.json"}]}