<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>山海经·大荒经</title>
    <meta name="generator" content="VuePress 1.4.1">
    <link rel="icon" href="/public/icon.ico">
    <link rel="stylesheet" href="http://cdn.be-sunshine.cn/winter.css">
    <meta name="description" content="理寺少卿,今天下太平,惟愿安康.">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    <link rel="preload" href="/public/assets/css/0.styles.78ae971e.css" as="style"><link rel="preload" href="/public/assets/js/app.f3b4c262.js" as="script"><link rel="preload" href="/public/assets/js/4.fc5870ef.js" as="script"><link rel="preload" href="/public/assets/js/1.71bf9aac.js" as="script"><link rel="preload" href="/public/assets/js/18.f4ee8baa.js" as="script"><link rel="prefetch" href="/public/assets/js/10.79fd5a44.js"><link rel="prefetch" href="/public/assets/js/100.11af7c4b.js"><link rel="prefetch" href="/public/assets/js/101.0af83de9.js"><link rel="prefetch" href="/public/assets/js/102.de9c7f39.js"><link rel="prefetch" href="/public/assets/js/103.761de70e.js"><link rel="prefetch" href="/public/assets/js/104.ea667698.js"><link rel="prefetch" href="/public/assets/js/105.3cb0dcc8.js"><link rel="prefetch" href="/public/assets/js/106.44aca55f.js"><link rel="prefetch" href="/public/assets/js/107.ebe5450d.js"><link rel="prefetch" href="/public/assets/js/108.d4bdbce6.js"><link rel="prefetch" href="/public/assets/js/109.0a49deb8.js"><link rel="prefetch" href="/public/assets/js/11.f7ba628d.js"><link rel="prefetch" href="/public/assets/js/110.af7cdf03.js"><link rel="prefetch" href="/public/assets/js/111.baaf9c4d.js"><link rel="prefetch" href="/public/assets/js/12.8c849b3f.js"><link rel="prefetch" href="/public/assets/js/13.f55ab279.js"><link rel="prefetch" href="/public/assets/js/14.de8926d7.js"><link rel="prefetch" href="/public/assets/js/15.6f61fbc9.js"><link rel="prefetch" href="/public/assets/js/16.c73c8e4f.js"><link rel="prefetch" href="/public/assets/js/17.81d5f875.js"><link rel="prefetch" href="/public/assets/js/19.46de4344.js"><link rel="prefetch" href="/public/assets/js/20.b6bd34d1.js"><link rel="prefetch" href="/public/assets/js/21.094a4da4.js"><link rel="prefetch" href="/public/assets/js/22.be4d5d91.js"><link rel="prefetch" href="/public/assets/js/23.e5af4488.js"><link rel="prefetch" href="/public/assets/js/24.4ae2739d.js"><link rel="prefetch" href="/public/assets/js/25.77ecbc25.js"><link rel="prefetch" href="/public/assets/js/26.e69f4c42.js"><link rel="prefetch" href="/public/assets/js/27.e1ca7c7e.js"><link rel="prefetch" href="/public/assets/js/28.fe3b9798.js"><link rel="prefetch" href="/public/assets/js/29.31705675.js"><link rel="prefetch" href="/public/assets/js/30.133c33a5.js"><link rel="prefetch" href="/public/assets/js/31.407badae.js"><link rel="prefetch" href="/public/assets/js/32.ac0213fb.js"><link rel="prefetch" href="/public/assets/js/33.91213e1d.js"><link rel="prefetch" href="/public/assets/js/34.ef529bb6.js"><link rel="prefetch" href="/public/assets/js/35.0751965d.js"><link rel="prefetch" href="/public/assets/js/36.1ddc3bc8.js"><link rel="prefetch" href="/public/assets/js/37.02e876d6.js"><link rel="prefetch" href="/public/assets/js/38.413ee793.js"><link rel="prefetch" href="/public/assets/js/39.8f3d5e40.js"><link rel="prefetch" href="/public/assets/js/40.5458b6b6.js"><link rel="prefetch" href="/public/assets/js/41.0156a656.js"><link rel="prefetch" href="/public/assets/js/42.b20a279c.js"><link rel="prefetch" href="/public/assets/js/43.4de5cc3c.js"><link rel="prefetch" href="/public/assets/js/44.1728a8f8.js"><link rel="prefetch" href="/public/assets/js/45.d1430b55.js"><link rel="prefetch" href="/public/assets/js/46.93470bc0.js"><link rel="prefetch" href="/public/assets/js/47.d4328fa3.js"><link rel="prefetch" href="/public/assets/js/48.16cfc654.js"><link rel="prefetch" href="/public/assets/js/49.5bdf15b5.js"><link rel="prefetch" href="/public/assets/js/5.23332061.js"><link rel="prefetch" href="/public/assets/js/50.b2617cb8.js"><link rel="prefetch" href="/public/assets/js/51.a93bc59f.js"><link rel="prefetch" href="/public/assets/js/52.289ae971.js"><link rel="prefetch" href="/public/assets/js/53.d7590005.js"><link rel="prefetch" href="/public/assets/js/54.2e045881.js"><link rel="prefetch" href="/public/assets/js/55.fa42ce75.js"><link rel="prefetch" href="/public/assets/js/56.dca3d428.js"><link rel="prefetch" href="/public/assets/js/57.c3e4d1a3.js"><link rel="prefetch" href="/public/assets/js/58.f2a4bfc8.js"><link rel="prefetch" href="/public/assets/js/59.3cbe909c.js"><link rel="prefetch" href="/public/assets/js/6.a11073e9.js"><link rel="prefetch" href="/public/assets/js/60.3aa1aa7c.js"><link rel="prefetch" href="/public/assets/js/61.8c03aa41.js"><link rel="prefetch" href="/public/assets/js/62.eb8c83e9.js"><link rel="prefetch" href="/public/assets/js/63.eaa29f28.js"><link rel="prefetch" href="/public/assets/js/64.93df603f.js"><link rel="prefetch" href="/public/assets/js/65.465cec05.js"><link rel="prefetch" href="/public/assets/js/66.b4c02bc5.js"><link rel="prefetch" href="/public/assets/js/67.19189bd2.js"><link rel="prefetch" href="/public/assets/js/68.4471a972.js"><link rel="prefetch" href="/public/assets/js/69.e30b7132.js"><link rel="prefetch" href="/public/assets/js/7.bcc0637b.js"><link rel="prefetch" href="/public/assets/js/70.233f45d5.js"><link rel="prefetch" href="/public/assets/js/71.4b1d6b8d.js"><link rel="prefetch" href="/public/assets/js/72.4b0be4d2.js"><link rel="prefetch" href="/public/assets/js/73.79c51307.js"><link rel="prefetch" href="/public/assets/js/74.43a0703a.js"><link rel="prefetch" href="/public/assets/js/75.e31d8013.js"><link rel="prefetch" href="/public/assets/js/76.b80caaf9.js"><link rel="prefetch" href="/public/assets/js/77.10c4f414.js"><link rel="prefetch" href="/public/assets/js/78.347cf842.js"><link rel="prefetch" href="/public/assets/js/79.a6c7f37a.js"><link rel="prefetch" href="/public/assets/js/8.8b908267.js"><link rel="prefetch" href="/public/assets/js/80.7934dad9.js"><link rel="prefetch" href="/public/assets/js/81.eea5aa44.js"><link rel="prefetch" href="/public/assets/js/82.23e348c3.js"><link rel="prefetch" href="/public/assets/js/83.9fc7d155.js"><link rel="prefetch" href="/public/assets/js/84.f97edbea.js"><link rel="prefetch" href="/public/assets/js/85.f8eeff8b.js"><link rel="prefetch" href="/public/assets/js/86.645620ff.js"><link rel="prefetch" href="/public/assets/js/87.f96f9041.js"><link rel="prefetch" href="/public/assets/js/88.3064129b.js"><link rel="prefetch" href="/public/assets/js/89.585c91d8.js"><link rel="prefetch" href="/public/assets/js/9.e4b36ef7.js"><link rel="prefetch" href="/public/assets/js/90.dd40a9e7.js"><link rel="prefetch" href="/public/assets/js/91.ce710778.js"><link rel="prefetch" href="/public/assets/js/92.80485932.js"><link rel="prefetch" href="/public/assets/js/93.83a6d253.js"><link rel="prefetch" href="/public/assets/js/94.bc06fef4.js"><link rel="prefetch" href="/public/assets/js/95.2074aab3.js"><link rel="prefetch" href="/public/assets/js/96.b20003da.js"><link rel="prefetch" href="/public/assets/js/97.39636a4c.js"><link rel="prefetch" href="/public/assets/js/98.c55fa990.js"><link rel="prefetch" href="/public/assets/js/99.5000c995.js"><link rel="prefetch" href="/public/assets/js/vendors~flowchart.6e39f720.js">
    <link rel="stylesheet" href="/public/assets/css/0.styles.78ae971e.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-19557b78><div data-v-19557b78><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-19557b78 data-v-19557b78><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-64685f0e data-v-19557b78 data-v-19557b78><h3 class="title" style="display:none;" data-v-64685f0e data-v-64685f0e>山海经·大荒经</h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-64685f0e data-v-64685f0e><input type="password" value="" data-v-64685f0e> <span data-v-64685f0e>Konck! Knock!</span> <button data-v-64685f0e>OK</button></label> <div class="footer" style="display:none;" data-v-64685f0e data-v-64685f0e><span data-v-64685f0e><i class="iconfont reco-theme" data-v-64685f0e></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-64685f0e>vuePress-theme-reco</a></span> <span data-v-64685f0e><i class="iconfont reco-copyright" data-v-64685f0e></i> <a data-v-64685f0e><span data-v-64685f0e>Winter</span>
            
          <span data-v-64685f0e>2017 - </span>
          2020
        </a></span></div></div> <div class="hide" data-v-19557b78><header class="navbar" data-v-19557b78><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/public/" class="home-link router-link-active"><img src="http://cdn.be-sunshine.cn/public/avatar.png" alt="山海经·大荒经" class="logo"> <span class="site-name">山海经·大荒经</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/public/" class="nav-link"><i class="iconfont reco-home"></i>
  主页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont undefined"></i>
      编程语言
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>Java</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  语言高级特性
</a></li><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  Spring技术栈
</a></li><li class="dropdown-subitem"><a href="/public/Java/Distribution/1.html" class="nav-link"><i class="iconfont undefined"></i>
  分布式
</a></li></ul></li><li class="dropdown-item"><h4>Python</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  语言高级特性
</a></li><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  Flask
</a></li><li class="dropdown-subitem"><a href="/public/programming_language/python/DataScience/numpy.html" class="nav-link"><i class="iconfont undefined"></i>
  Numpy
</a></li><li class="dropdown-subitem"><a href="/public/note/fractal/Koch.html" class="nav-link"><i class="iconfont undefined"></i>
  Processing 分形
</a></li></ul></li><li class="dropdown-item"><h4>C++</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/public/note/G1M/Cpp/Cplus.html" class="nav-link"><i class="iconfont undefined"></i>
  高级语法
</a></li><li class="dropdown-subitem"><a href="/public/note/leetcode/LC1.html" class="nav-link"><i class="iconfont undefined"></i>
  LeetCode
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont undefined"></i>
      通用技能
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/public/general/mysql/mysql.html" class="nav-link"><i class="iconfont undefined"></i>
  MySql
</a></li><li class="dropdown-item"><!----> <a href="/public/algorithm/dp/dp.html" class="nav-link"><i class="iconfont undefined"></i>
  算法
</a></li><li class="dropdown-item"><!----> <a href="/public/note/G1M/advance_ds/priority_queue.html" class="nav-link"><i class="iconfont undefined"></i>
  高级数据结构
</a></li><li class="dropdown-item"><!----> <a href="/public/note/G1M/Digital_Image/Introduce.html" class="nav-link"><i class="iconfont undefined"></i>
  数字图像处理
</a></li><li class="dropdown-item"><!----> <a href="/public/note/G1M/Computer_Graphics/Computer_Graphics.html" class="nav-link"><i class="iconfont undefined"></i>
  计算机图形学
</a></li><li class="dropdown-item"><!----> <a href="/public/note/G1M/mode/matlab.html" class="nav-link"><i class="iconfont undefined"></i>
  数学建模
</a></li><li class="dropdown-item"><h4>人工智能</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/public/Tensorflow2/tf2/Tensorflow_Keras/Keras.html" class="nav-link"><i class="iconfont undefined"></i>
  Tensorflow
</a></li><li class="dropdown-subitem"><a href="/public/ai/ml/Modle_Represen.html" class="nav-link"><i class="iconfont undefined"></i>
  机器学习
</a></li><li class="dropdown-subitem"><a href="/public/ai/dl/about.html" class="nav-link"><i class="iconfont undefined"></i>
  神经网络
</a></li></ul></li><li class="dropdown-item"><h4>游戏/VR/AR开发</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/public/xr/vr/Unity.html" class="nav-link"><i class="iconfont undefined"></i>
  VR
</a></li><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  AR
</a></li><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  GameMakerStudio
</a></li></ul></li><li class="dropdown-item"><!----> <a href="/public/web/es6.html" class="nav-link"><i class="iconfont undefined"></i>
  前端
</a></li><li class="dropdown-item"><!----> <a href="/public/note/Design_pattern/facade.html" class="nav-link"><i class="iconfont undefined"></i>
  设计模式
</a></li><li class="dropdown-item"><!----> <a href="/public/general/mysql/mysql.html" class="nav-link"><i class="iconfont undefined"></i>
  数据库
</a></li></ul></div></div><div class="nav-item"><a href="/public/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/public/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/834930269" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li><li class="dropdown-item"><!----> <a href="http://be-sunshine.cn" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont undefined"></i>
  hexo博客
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-19557b78></div> <aside class="sidebar" data-v-19557b78><div class="personal-info-wrapper" data-v-042e23d4><img src="http://cdn.be-sunshine.cn/public/avatar.png" alt="author-avatar" class="personal-img" data-v-042e23d4> <h3 class="name" data-v-042e23d4>
    Winter
  </h3> <div class="num" data-v-042e23d4><div data-v-042e23d4><h3 data-v-042e23d4>54</h3> <h6 data-v-042e23d4>Article</h6></div> <div data-v-042e23d4><h3 data-v-042e23d4>24</h3> <h6 data-v-042e23d4>Tag</h6></div></div> <hr data-v-042e23d4></div> <nav class="nav-links"><div class="nav-item"><a href="/public/" class="nav-link"><i class="iconfont reco-home"></i>
  主页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont undefined"></i>
      编程语言
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>Java</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  语言高级特性
</a></li><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  Spring技术栈
</a></li><li class="dropdown-subitem"><a href="/public/Java/Distribution/1.html" class="nav-link"><i class="iconfont undefined"></i>
  分布式
</a></li></ul></li><li class="dropdown-item"><h4>Python</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  语言高级特性
</a></li><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  Flask
</a></li><li class="dropdown-subitem"><a href="/public/programming_language/python/DataScience/numpy.html" class="nav-link"><i class="iconfont undefined"></i>
  Numpy
</a></li><li class="dropdown-subitem"><a href="/public/note/fractal/Koch.html" class="nav-link"><i class="iconfont undefined"></i>
  Processing 分形
</a></li></ul></li><li class="dropdown-item"><h4>C++</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/public/note/G1M/Cpp/Cplus.html" class="nav-link"><i class="iconfont undefined"></i>
  高级语法
</a></li><li class="dropdown-subitem"><a href="/public/note/leetcode/LC1.html" class="nav-link"><i class="iconfont undefined"></i>
  LeetCode
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont undefined"></i>
      通用技能
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/public/general/mysql/mysql.html" class="nav-link"><i class="iconfont undefined"></i>
  MySql
</a></li><li class="dropdown-item"><!----> <a href="/public/algorithm/dp/dp.html" class="nav-link"><i class="iconfont undefined"></i>
  算法
</a></li><li class="dropdown-item"><!----> <a href="/public/note/G1M/advance_ds/priority_queue.html" class="nav-link"><i class="iconfont undefined"></i>
  高级数据结构
</a></li><li class="dropdown-item"><!----> <a href="/public/note/G1M/Digital_Image/Introduce.html" class="nav-link"><i class="iconfont undefined"></i>
  数字图像处理
</a></li><li class="dropdown-item"><!----> <a href="/public/note/G1M/Computer_Graphics/Computer_Graphics.html" class="nav-link"><i class="iconfont undefined"></i>
  计算机图形学
</a></li><li class="dropdown-item"><!----> <a href="/public/note/G1M/mode/matlab.html" class="nav-link"><i class="iconfont undefined"></i>
  数学建模
</a></li><li class="dropdown-item"><h4>人工智能</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/public/Tensorflow2/tf2/Tensorflow_Keras/Keras.html" class="nav-link"><i class="iconfont undefined"></i>
  Tensorflow
</a></li><li class="dropdown-subitem"><a href="/public/ai/ml/Modle_Represen.html" class="nav-link"><i class="iconfont undefined"></i>
  机器学习
</a></li><li class="dropdown-subitem"><a href="/public/ai/dl/about.html" class="nav-link"><i class="iconfont undefined"></i>
  神经网络
</a></li></ul></li><li class="dropdown-item"><h4>游戏/VR/AR开发</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/public/xr/vr/Unity.html" class="nav-link"><i class="iconfont undefined"></i>
  VR
</a></li><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  AR
</a></li><li class="dropdown-subitem"><a href="/public/" class="nav-link"><i class="iconfont undefined"></i>
  GameMakerStudio
</a></li></ul></li><li class="dropdown-item"><!----> <a href="/public/web/es6.html" class="nav-link"><i class="iconfont undefined"></i>
  前端
</a></li><li class="dropdown-item"><!----> <a href="/public/note/Design_pattern/facade.html" class="nav-link"><i class="iconfont undefined"></i>
  设计模式
</a></li><li class="dropdown-item"><!----> <a href="/public/general/mysql/mysql.html" class="nav-link"><i class="iconfont undefined"></i>
  数据库
</a></li></ul></div></div><div class="nav-item"><a href="/public/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/public/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/834930269" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li><li class="dropdown-item"><!----> <a href="http://be-sunshine.cn" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont undefined"></i>
  hexo博客
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></div></div> <!----></nav>  <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-64685f0e data-v-19557b78><h3 class="title" style="display:none;" data-v-64685f0e data-v-64685f0e></h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-64685f0e data-v-64685f0e><input type="password" value="" data-v-64685f0e> <span data-v-64685f0e>Konck! Knock!</span> <button data-v-64685f0e>OK</button></label> <div class="footer" style="display:none;" data-v-64685f0e data-v-64685f0e><span data-v-64685f0e><i class="iconfont reco-theme" data-v-64685f0e></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-64685f0e>vuePress-theme-reco</a></span> <span data-v-64685f0e><i class="iconfont reco-copyright" data-v-64685f0e></i> <a data-v-64685f0e><span data-v-64685f0e>Winter</span>
            
          <span data-v-64685f0e>2017 - </span>
          2020
        </a></span></div></div> <div data-v-19557b78><main class="page"><div class="page-title" style="display:none;"><h1></h1> <hr> <div data-v-34ea29db><i class="iconfont reco-account" data-v-34ea29db><span data-v-34ea29db>Winter</span></i> <!----> <i class="iconfont reco-eye" data-v-34ea29db><span id="/public/Tensorflow2/tf2/Base/pku.html" data-flag-title="Your Article Title" class="leancloud-visitors" data-v-34ea29db><a class="leancloud-visitors-count" style="font-size:.9rem;font-weight:normal;color:#999;"></a></span></i> <!----></div></div> <div class="theme-reco-content content__default" style="display:none;"><p>+---
title: Tensorflow2-pku笔记
sidebarDepth: 4
meta:</p> <ul><li>name: description
content: Tensorflow2笔记</li> <li>name: keywords
content: Tensorflow2</li></ul> <hr> <p></p><div class="table-of-contents"><ul><li><a href="#张量生成">张量生成</a><ul><li><a href="#数据类型">数据类型</a></li><li><a href="#创建一个tensor">创建一个Tensor</a></li><li><a href="#numpy转tensor">numpy转tensor</a></li><li><a href="#其他创建张量方法">其他创建张量方法</a></li></ul></li><li><a href="#常用函数">常用函数</a><ul><li><a href="#对于二维张量的axis">对于二维张量的axis</a></li><li><a href="#举例">举例</a></li><li><a href="#tf-variable">tf.Variable</a></li><li><a href="#数学运算">数学运算</a></li><li><a href="#data">data</a></li><li><a href="#tf-gradienttape">tf.GradientTape</a></li><li><a href="#enumerate">enumerate</a></li><li><a href="#tf-one-hot">tf.one_hot</a></li><li><a href="#tf-nn-softmax">tf.nn.softmax</a></li><li><a href="#assign-sub">assign_sub</a></li><li><a href="#tf-argmax">tf.argmax</a></li><li><a href="#鸢尾花">鸢尾花</a></li><li><a href="#神经网络实现鸢尾花分类">神经网络实现鸢尾花分类</a></li></ul></li><li><a href="#优化器">优化器</a><ul><li><a href="#tf-where">tf.where</a></li><li><a href="#np-random-randomstate-rand">np.random.RandomState.rand()</a></li><li><a href="#np-vstack">np.vstack()</a></li><li><a href="#生成网格坐标点">生成网格坐标点</a></li><li><a href="#复杂学习率">复杂学习率</a></li><li><a href="#激活函数">激活函数</a></li><li><a href="#损失函数">损失函数</a></li><li><a href="#缓解过拟合">缓解过拟合</a></li></ul></li><li><a href="#神经网络八股-使用keras">神经网络八股(使用keras)</a><ul><li><a href="#六步法">六步法</a></li><li><a href="#sequential-网络结构">Sequential([网络结构])</a></li><li><a href="#八股-class">八股(class)</a></li></ul></li></ul></div><p></p> <h1 id="tensorflow2-pku"><a href="#tensorflow2-pku" class="header-anchor">#</a> Tensorflow2-pku</h1> <h2 id="张量生成"><a href="#张量生成" class="header-anchor">#</a> 张量生成</h2> <blockquote><p>即多维数组,一阶称为向量,二阶称为矩阵,n阶统称为张量</p></blockquote> <h3 id="数据类型"><a href="#数据类型" class="header-anchor">#</a> 数据类型</h3> <blockquote><p>tf.int,tf.float</p> <blockquote><p>tf.int32,tf.float32,tf.float64
tf.bool
tf.constant([True,False])
tf.string
tf.constant(&quot;Hello,world!&quot;)</p></blockquote></blockquote> <h3 id="创建一个tensor"><a href="#创建一个tensor" class="header-anchor">#</a> 创建一个Tensor</h3> <blockquote><p>tf.constant(张量内容,dtype=数据类型(可选))</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment"># 结果</span>
<span class="token triple-quoted-string string">'''
tf.Tensor([1 5], shape=(2,), dtype=int64)
&lt;dtype: 'int64'&gt;
(2,)
'''</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><h3 id="numpy转tensor"><a href="#numpy转tensor" class="header-anchor">#</a> numpy转tensor</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
a <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>convert_to_tensor<span class="token punctuation">(</span>a<span class="token punctuation">,</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h3 id="其他创建张量方法"><a href="#其他创建张量方法" class="header-anchor">#</a> 其他创建张量方法</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>维度<span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>维度<span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>fill<span class="token punctuation">(</span>维度<span class="token punctuation">,</span>指定值<span class="token punctuation">)</span>

a<span class="token operator">=</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>fill<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><div class="language-python line-numbers-mode"><pre class="language-python"><code>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>维度<span class="token punctuation">,</span>mean<span class="token operator">=</span>均值<span class="token punctuation">,</span>stddev<span class="token operator">=</span>标准差<span class="token punctuation">)</span>
<span class="token comment"># 默认均值0,标准差1,正态分布随机数</span>

<span class="token comment"># 截断式正态分布随机数,数据集中在均值附近</span>
tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span>维度<span class="token punctuation">,</span>mean<span class="token operator">=</span>均值<span class="token punctuation">,</span>stddev<span class="token operator">=</span>标准差<span class="token punctuation">)</span>

d <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span>

e <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''
tf.Tensor(
[[ 1.3927269   0.06218731]
 [-0.8482692  -0.81205285]], shape=(2, 2), dtype=float32)
tf.Tensor(
[[ 1.7386221   0.0458321 ]
 [ 0.51848936 -0.32362974]], shape=(2, 2), dtype=float32)

'''</span>


<span class="token comment"># 生成均匀分布随机数[min,max)</span>
tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span>维度<span class="token punctuation">,</span>minval<span class="token operator">=</span>最小值<span class="token punctuation">,</span>maxval<span class="token operator">=</span>最大值<span class="token punctuation">)</span>
f <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>minval<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>maxval<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><h2 id="常用函数"><a href="#常用函数" class="header-anchor">#</a> 常用函数</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 强制tensor转换为该数据类型</span>
tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>张量名<span class="token punctuation">,</span>dtype<span class="token operator">=</span>数据类型<span class="token punctuation">)</span>

<span class="token comment"># 计算张量维度上元素的最小值</span>
tf<span class="token punctuation">.</span>reduce_min<span class="token punctuation">(</span>张量名<span class="token punctuation">)</span>

<span class="token comment"># 计算张量维度上元素的最大值</span>
tf<span class="token punctuation">.</span>reduce_max<span class="token punctuation">(</span>张量名<span class="token punctuation">)</span>

x1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float64<span class="token punctuation">)</span>
x2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x1<span class="token punctuation">,</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><h3 id="对于二维张量的axis"><a href="#对于二维张量的axis" class="header-anchor">#</a> 对于二维张量的axis</h3> <blockquote><p>axis指定是控制行维度还是列为度</p> <blockquote><p>axis=0代表跨行(逐列),axis=1代表跨列(逐行)
不指定axis,则所有元素参与计算</p></blockquote></blockquote> <h3 id="举例"><a href="#举例" class="header-anchor">#</a> 举例</h3> <blockquote><p>求平均值</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>张量名<span class="token punctuation">,</span>axis<span class="token operator">=</span>操作轴<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><blockquote><p>求和</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>张量名<span class="token punctuation">,</span>axis<span class="token operator">=</span>操作轴<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language-python line-numbers-mode"><pre class="language-python"><code>x <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>x<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h3 id="tf-variable"><a href="#tf-variable" class="header-anchor">#</a> tf.Variable</h3> <blockquote><p>tf.Varliable()<code>将变量标记为&quot;可训练&quot;</code>,被标记的变量会在反向传播中记录梯度信息,神经网络训练中,常用该函数标记待训练参数</p></blockquote> <h3 id="数学运算"><a href="#数学运算" class="header-anchor">#</a> 数学运算</h3> <blockquote><p>四则运算</p> <blockquote><p>tf.add,tf.subtract,tf.multiply,tf.divide</p> <blockquote><p>参数(张量1,张量2)</p></blockquote></blockquote></blockquote> <blockquote><p>平方,次方与开方</p> <blockquote><p>tf.square,tf.pow,tf.sqrt</p></blockquote></blockquote> <blockquote><p>矩阵乘</p> <blockquote><p>tf.matmul</p></blockquote></blockquote> <h3 id="data"><a href="#data" class="header-anchor">#</a> data</h3> <blockquote><p>神经网络训练时,是将标签和数据配对后再进行计算的</p></blockquote> <blockquote><p>tf.data.Dataset.from_tensor_slices</p></blockquote> <blockquote><p>切分传入张量的第一维度,生成输入特征/标签对,构建数据集 data = tf.data.Dataset.from_tensor_slices((输入特征,标签))</p></blockquote> <blockquote><p>numpy和tensor格式都可以用该语句读入数据</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code>features <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
labels <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>

<span class="token keyword">for</span> elem <span class="token keyword">in</span> dataset<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>elem<span class="token punctuation">)</span>

<span class="token comment"># 输出</span>
<span class="token triple-quoted-string string">'''
&lt;TensorSliceDataset shapes: ((), ()), types: (tf.int32, tf.int32)&gt;
(&lt;tf.Tensor: id=997, shape=(), dtype=int32, numpy=12&gt;, &lt;tf.Tensor: id=998, shape=(), dtype=int32, numpy=0&gt;)
(&lt;tf.Tensor: id=999, shape=(), dtype=int32, numpy=23&gt;, &lt;tf.Tensor: id=1000, shape=(), dtype=int32, numpy=1&gt;)
(&lt;tf.Tensor: id=1001, shape=(), dtype=int32, numpy=10&gt;, &lt;tf.Tensor: id=1002, shape=(), dtype=int32, numpy=1&gt;)
(&lt;tf.Tensor: id=1003, shape=(), dtype=int32, numpy=17&gt;, &lt;tf.Tensor: id=1004, shape=(), dtype=int32, numpy=0&gt;)

'''</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><h3 id="tf-gradienttape"><a href="#tf-gradienttape" class="header-anchor">#</a> tf.GradientTape</h3> <blockquote><p>with 结构记录计算过程，gradient求出张量的梯度
with tf.GradientTape() as tape:
若干个计算过程
grad = tape.gradient(函数,对谁求导)</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientType<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>
	w <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">3.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	loss <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment"># 损失函数是w^2,对w求导</span>
grad <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss<span class="token punctuation">,</span>w<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>grad<span class="token punctuation">)</span>

<span class="token comment"># 运行结果: tf.Tensor(6.0,shape=(),dtype=float32)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h3 id="enumerate"><a href="#enumerate" class="header-anchor">#</a> enumerate</h3> <blockquote><p>enumerate是python的内建函数,他可遍历每个元素(如列表,元祖,或字符串),结合为: 索引,元素,常在for循环中使用。
enumerate(列表名)</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code>seq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'one'</span><span class="token punctuation">,</span><span class="token string">'two'</span><span class="token punctuation">,</span><span class="token string">'three'</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span>elem <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>seq<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>elem<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h3 id="tf-one-hot"><a href="#tf-one-hot" class="header-anchor">#</a> tf.one_hot</h3> <blockquote><p>独热编码: 在分类问题中,常用独热码作为标签.
tf.one_hot(待转换数据,depth=几分类)</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code>classes<span class="token operator">=</span><span class="token number">3</span>
labels <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
output<span class="token operator">=</span>tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>labels<span class="token punctuation">,</span>depth<span class="token operator">=</span>classes<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''
tf.Tensor(
[[0. 1. 0.]
 [1. 0. 0.]
 [0. 0. 1.]], shape=(3, 3), dtype=float32)
'''</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h3 id="tf-nn-softmax"><a href="#tf-nn-softmax" class="header-anchor">#</a> tf.nn.softmax</h3> <p><img src="http://cdn.be-sunshine.cn/pku_softmax.png" alt=""></p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>y <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.01</span><span class="token punctuation">,</span><span class="token number">2.01</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.66</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_pro <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;After softmax,y_pro is: &quot;</span><span class="token punctuation">,</span>y_pro<span class="token punctuation">)</span>

<span class="token comment"># 输出</span>
<span class="token triple-quoted-string string">'''
After softmax,y_pro is:  tf.Tensor([0.25598174 0.69583046 0.0481878 ], shape=(3,), dtype=float32)
'''</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h3 id="assign-sub"><a href="#assign-sub" class="header-anchor">#</a> assign_sub</h3> <blockquote><p>赋值操作,更新参数的值并返回
调用assign_sub前,先用tf.Variable定义变量w为可训练(可自更新)
w.assign_sub(w要自减的内容)</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code>w <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
w<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h3 id="tf-argmax"><a href="#tf-argmax" class="header-anchor">#</a> tf.argmax</h3> <blockquote><p>返回张量沿制定维度最大值的索引 tf.argmax(张量名,axis=操作轴)</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>test<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 返回每一列最大值的索引</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="鸢尾花"><a href="#鸢尾花" class="header-anchor">#</a> 鸢尾花</h3> <h4 id="读入数据"><a href="#读入数据" class="header-anchor">#</a> 读入数据</h4> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> pandas <span class="token keyword">import</span> DataFrame
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

x_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data <span class="token comment"># 读取所有数据</span>
y_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>target <span class="token comment"># 所有标签</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;x_data from datasets: \n&quot;</span><span class="token punctuation">,</span>x_data<span class="token punctuation">)</span>

<span class="token comment"># 使用DataFrame为每一列增加中文注释</span>
x_data <span class="token operator">=</span> DataFrame<span class="token punctuation">(</span>x_data<span class="token punctuation">,</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;花萼长度&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;花萼宽度&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;花瓣长度&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;花瓣宽度&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
pd<span class="token punctuation">.</span>set_option<span class="token punctuation">(</span><span class="token string">'display.unicode.east_asian_width'</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment"># 设置列名对齐</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x_data add index:\n'</span><span class="token punctuation">,</span>x_data<span class="token punctuation">)</span>

x_data<span class="token punctuation">[</span><span class="token string">'类别'</span><span class="token punctuation">]</span> <span class="token operator">=</span> y_data <span class="token comment">#添加一列</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x_data add a column: \n'</span><span class="token punctuation">,</span>x_data<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code># 输出
x_data add index:
      花萼长度  花萼宽度  花瓣长度  花瓣宽度
0         5.1       3.5       1.4       0.2
1         4.9       3.0       1.4       0.2
2         4.7       3.2       1.3       0.2
3         4.6       3.1       1.5       0.2
4         5.0       3.6       1.4       0.2
					...
21        5.1       3.7       1.5       0.4
146       6.3       2.5       5.0       1.9
147       6.5       3.0       5.2       2.0
148       6.2       3.4       5.4       2.3
149       5.9       3.0       5.1       1.8

[150 rows x 4 columns]
x_data add a column: 
      花萼长度  花萼宽度  花瓣长度  花瓣宽度  类别
0         5.1       3.5       1.4       0.2     0
1         4.9       3.0       1.4       0.2     0
2         4.7       3.2       1.3       0.2     0
3         4.6       3.1       1.5       0.2     0
4         5.0       3.6       1.4       0.2     0
5         5.4       3.9       1.7       0.4     0
6         4.6       3.4       1.4       0.3     0
7         5.0       3.4       1.5       0.2     0
..        ...       ...       ...       ...   ...
142       5.8       2.7       5.1       1.9     2
143       6.8       3.2       5.9       2.3     2
144       6.7       3.3       5.7       2.5     2
145       6.7       3.0       5.2       2.3     2
146       6.3       2.5       5.0       1.9     2
147       6.5       3.0       5.2       2.0     2
148       6.2       3.4       5.4       2.3     2
149       5.9       3.0       5.1       1.8     2

[150 rows x 5 columns]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br></div></div><h3 id="神经网络实现鸢尾花分类"><a href="#神经网络实现鸢尾花分类" class="header-anchor">#</a> 神经网络实现鸢尾花分类</h3> <ul><li>准备数据
<ul><li>数据集读入</li> <li>数据集乱序</li> <li>生成训练集和测试集</li> <li>配成(输入特征,标签)对,每次读入一小撮(batch)</li></ul></li> <li>搭建网络
<ul><li>定义神经网络中所有可训练参数</li></ul></li> <li>参数优化
<ul><li>嵌套循环迭代,with结构更新参数,显示当前loss</li></ul></li> <li>测试效果
<ul><li>计算当前参数前向传播后的准确率,显示当前acc</li></ul></li> <li>acc/loss可视化</li></ul> <h4 id="代码"><a href="#代码" class="header-anchor">#</a> 代码</h4> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> pandas <span class="token keyword">import</span> DataFrame
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np 
<span class="token keyword">import</span> os
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">&quot;-1&quot;</span>    
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> matplotlib

x_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data <span class="token comment"># 读取所有数据</span>
y_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>target <span class="token comment"># 所有标签</span>

<span class="token comment"># 数据集乱序</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>y_data<span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>set_seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>

<span class="token comment"># 数据集分出永不相见的训练集和测试集</span>
x_train <span class="token operator">=</span> x_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">]</span>
y_train <span class="token operator">=</span> y_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">]</span>
x_test <span class="token operator">=</span> x_data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
y_test <span class="token operator">=</span> y_data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
<span class="token comment"># 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错</span>
x_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
x_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

<span class="token comment"># 配对打包,配置batch，以batch为单位输入神经网络</span>
train_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
test_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>

<span class="token comment"># 定义可训练参数</span>
w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
b1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#定义超参数</span>
lr <span class="token operator">=</span> <span class="token number">0.1</span>
train_loss_results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
test_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
epoch <span class="token operator">=</span> <span class="token number">500</span>
loss_all <span class="token operator">=</span> <span class="token number">0</span>

<span class="token comment"># 嵌套循环迭代,with结构更新参数,显示当前loss</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#数据集级别迭代</span>
    <span class="token keyword">for</span> step<span class="token punctuation">,</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_db<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#batch级别迭代</span>
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span> <span class="token comment">#记录梯度信息</span>
            <span class="token comment">#面向传播过程计算y</span>
            y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>w1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
            y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token comment">#softmax不是损失函数,只是变成概率形式</span>
            y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span>depth<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
            loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>y_ <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 均方误差损失函数</span>
            loss_all <span class="token operator">+=</span> loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment">#计算总loss</span>
        grads <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss<span class="token punctuation">,</span><span class="token punctuation">[</span>w1<span class="token punctuation">,</span>b1<span class="token punctuation">]</span><span class="token punctuation">)</span>
        w1<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span>lr<span class="token operator">*</span>grads<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 参数自更新</span>
        b1<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span>lr<span class="token operator">*</span>grads<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Epoch {},loss: {}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss_all<span class="token operator">/</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 因为每个epoch会有四个step,所以求这四个stpe的平均值</span>
    train_loss_results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss_all <span class="token operator">/</span> <span class="token number">4</span><span class="token punctuation">)</span>
    loss_all <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment">#重新初始化</span>
    
    <span class="token comment">#测试</span>
    total_correct<span class="token punctuation">,</span>total_number <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    <span class="token keyword">for</span> x_test<span class="token punctuation">,</span>y_test <span class="token keyword">in</span> test_db<span class="token punctuation">:</span>
        <span class="token comment">#使用更新后的参数</span>
        y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>w1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
        y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 返回y中最大值的索引,即预测的分类</span>
        pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>pred<span class="token punctuation">,</span>dtype<span class="token operator">=</span>y_test<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
        correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>pred<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
        correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>correct<span class="token punctuation">)</span> <span class="token comment">#即正确的个数</span>
        total_correct <span class="token operator">+=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>correct<span class="token punctuation">)</span>
        total_number <span class="token operator">+=</span> x_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    acc <span class="token operator">=</span> total_correct <span class="token operator">/</span> total_number
    test_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'test_acc: '</span><span class="token punctuation">,</span>acc<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'---------------------------------------'</span><span class="token punctuation">)</span>
    
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token comment"># loss 曲线</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Loss Function Curve'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_loss_results<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'$Loss$'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#画出曲线图标</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br></div></div><div class="language- line-numbers-mode"><pre class="language-text"><code>部分输出:
Epoch 4,loss: 0.19942264631390572
test_acc:  0.16666666666666666
---------------------------------------
Epoch 5,loss: 0.18873637914657593
test_acc:  0.5
---------------------------------------
Epoch 6,loss: 0.17851300165057182
test_acc:  0.5333333333333333
---------------------------------------
Epoch 7,loss: 0.16922876238822937
test_acc:  0.5333333333333333
---------------------------------------
Epoch 499,loss: 0.03230027528479695
test_acc:  1.0
---------------------------------------
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><h2 id="优化器"><a href="#优化器" class="header-anchor">#</a> 优化器</h2> <h3 id="tf-where"><a href="#tf-where" class="header-anchor">#</a> tf.where</h3> <blockquote><p>条件语句真返回A,假返回B</p> <blockquote><p>tf.where(条件语句,A,B)</p></blockquote></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>where<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>greater<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span> <span class="token comment"># 若a&gt;b,为真</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;c:&quot;</span><span class="token punctuation">,</span>c<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="np-random-randomstate-rand"><a href="#np-random-randomstate-rand" class="header-anchor">#</a> np.random.RandomState.rand()</h3> <blockquote><p>返回一个[0,1)之间的随机数
np.random.RandomState.rand(维度) # 维度为空则返回标量</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
rdm <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>RandomState<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment"># 返回维度为2行3列随机数矩阵</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;a:&quot;</span><span class="token punctuation">,</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;b:&quot;</span><span class="token punctuation">,</span>b<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><h3 id="np-vstack"><a href="#np-vstack" class="header-anchor">#</a> np.vstack()</h3> <blockquote><p>将两个数组按垂直方向叠加
np.vstack(数组1,数组2)</p></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;c:\n&quot;</span><span class="token punctuation">,</span>c<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''
c:
[[1 2 3]
[4 5 6]]
'''</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h3 id="生成网格坐标点"><a href="#生成网格坐标点" class="header-anchor">#</a> 生成网格坐标点</h3> <blockquote><p>np.mgrid[]</p> <blockquote><p>np.mgrid[起始值:结束值:步长,起始值:结束值:步长,...]</p> <blockquote><p>[A,B)
也可以a🅱️cj
[a,b)区间内取c个点</p></blockquote></blockquote></blockquote> <blockquote><p>x.ravel()</p> <blockquote><p>将x变成一维数组</p></blockquote></blockquote> <blockquote><p>np.c_[] 使返回的间隔数值点配对</p> <blockquote><p>np.c_[数组1,数组2,...]</p></blockquote></blockquote> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
x<span class="token punctuation">,</span>y <span class="token operator">=</span> np<span class="token punctuation">.</span>mgrid<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token number">0.5</span><span class="token punctuation">]</span>
grid <span class="token operator">=</span> np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>x<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>y<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;x:&quot;</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;y:&quot;</span><span class="token punctuation">,</span>y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;grid:\n&quot;</span><span class="token punctuation">,</span>grid<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''
x: [[1. 1. 1. 1.]
 [2. 2. 2. 2.]]
y: [[2.  2.5 3.  3.5]
 [2.  2.5 3.  3.5]]
grid:
 [[1.  2. ]
 [1.  2.5]
 [1.  3. ]
 [1.  3.5]
 [2.  2. ]
 [2.  2.5]
 [2.  3. ]
 [2.  3.5]]

'''</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br></div></div><h3 id="复杂学习率"><a href="#复杂学习率" class="header-anchor">#</a> 复杂学习率</h3> <h4 id="指数衰减学习率"><a href="#指数衰减学习率" class="header-anchor">#</a> 指数衰减学习率</h4> <blockquote><p>可以先用较大的学习率,快速得到较优解,然后逐步减小学习率,使模型在训练后期稳定
指数衰减学习率 = 初始学习率*学习率衰减率^(当前论述/多少轮衰减一次)</p></blockquote> <h3 id="激活函数"><a href="#激活函数" class="header-anchor">#</a> 激活函数</h3> <blockquote><p>用于使模型变成非线性</p></blockquote> <h4 id="sigmoid"><a href="#sigmoid" class="header-anchor">#</a> sigmoid</h4> <blockquote><p>tf.nn.sigmoid(x)</p></blockquote> <ul><li>易造成梯度消失</li> <li>输出非0均值,收敛慢</li> <li>幂运算复杂,训练时间长</li></ul> <h4 id="relu"><a href="#relu" class="header-anchor">#</a> relu</h4> <blockquote><p>tf.nn.relu(x)</p></blockquote> <blockquote><p>优点</p></blockquote> <ul><li>解决了梯度消失问题(在正区间)</li> <li>只需判断输入是否大于0,计算速度块</li> <li>收敛速度远快于sigmoid和tanh</li></ul> <blockquote><p>缺点</p></blockquote> <ul><li>输出非0均值,收敛慢</li> <li>缺失Relu问题,某些神经元网络可能永远不会被激活,导致的相应参数永远不会被更新</li></ul> <h4 id="leaky-relu"><a href="#leaky-relu" class="header-anchor">#</a> Leaky Relu</h4> <blockquote><p>tf.nn.leaky_relu(x)
理论上优于relu,但是没有完全证明leakyrelu总是优于relu</p></blockquote> <h3 id="损失函数"><a href="#损失函数" class="header-anchor">#</a> 损失函数</h3> <blockquote><p>预测值(y)与已知答案(y_)的差距</p> <blockquote><p>NN优化目标: loss最小</p></blockquote></blockquote> <blockquote><p>主流loss</p></blockquote> <ul><li>mse 均方误差</li> <li>自定义</li> <li>ce(cross entropy) 交叉熵</li></ul> <h4 id="均方误差mse"><a href="#均方误差mse" class="header-anchor">#</a> 均方误差mse</h4> <blockquote><p>loss_mse = tf.reduce_mean(tf.square(y_-y))</p></blockquote> <h4 id="自定义损失函数"><a href="#自定义损失函数" class="header-anchor">#</a> 自定义损失函数</h4> <blockquote><p>这点建议自己去看下，pku的tensorflow22.4节</p></blockquote> <p>       关键为了解决: 预测多了,损失成本.预测少了,损失利润.而我们的均方误差损失函数默认的是无论预测多还是少均是损失&quot;成本&quot;</p> <h4 id="交叉熵损失函数ce"><a href="#交叉熵损失函数ce" class="header-anchor">#</a> 交叉熵损失函数ce</h4> <blockquote><p>表示两个概率分布之间的距离</p> <blockquote><p>常用在one-hot一类的概率表示法中</p></blockquote></blockquote> <h3 id="缓解过拟合"><a href="#缓解过拟合" class="header-anchor">#</a> 缓解过拟合</h3> <blockquote><p>欠拟合的解决方法</p></blockquote> <ul><li>增加输入特征项</li> <li>增加网络参数</li> <li>减少正则化参数</li></ul> <blockquote><p>过拟合的解决方法</p></blockquote> <ul><li>数据清洗</li> <li>增大训练集</li> <li>采用正则化</li> <li>增大正则化参数</li></ul> <h4 id="正则化缓解过拟合"><a href="#正则化缓解过拟合" class="header-anchor">#</a> 正则化缓解过拟合</h4> <p>.</p> <h4 id="优化器-2"><a href="#优化器-2" class="header-anchor">#</a> 优化器</h4> <p>.</p> <h2 id="神经网络八股-使用keras"><a href="#神经网络八股-使用keras" class="header-anchor">#</a> 神经网络八股(使用keras)</h2> <h3 id="六步法"><a href="#六步法" class="header-anchor">#</a> 六步法</h3> <ul><li>import</li> <li>train,test数据集</li> <li>model = tf.keras.models.Sequential</li> <li>model.compile</li> <li>model.fit</li> <li>model.summary</li></ul> <h3 id="sequential-网络结构"><a href="#sequential-网络结构" class="header-anchor">#</a> Sequential([网络结构])</h3> <blockquote><p>举例:</p></blockquote> <ul><li>拉直层: tf.keras.layers.Fatten() #将Nd的数据拉直成1D</li> <li>全连接层: tf.keras.layers.Dense(神经元个数,activation=&quot;激活函数&quot;,kernel_regularizer=哪种正则化)
<ul><li>activation(字符串给出)可选: relu、softmax、sigmoid、tanh</li> <li>kernel_regularizer可选: tf.keras.regularizers.l1()、tf.keras.regularizers.l2()</li></ul></li> <li>卷积层: tf.keras.layers.Conv2D(filters=卷积核个数,kernel_size=卷几何尺寸,strides=卷及步长,padding=&quot;valid&quot; or &quot;same&quot;)</li> <li>LSTM层: tf.keras.layers.LSTM()</li> <li>model.compile(optimizer=优化器,loss=损失函数,metrics=[&quot;评测指标&quot;])
<ul><li>OPTIMIZER可选:
<ul><li>'sgd' or tf.keras.optimizers.SGD(lr=学习率,momentum=栋梁参数)</li> <li>'adagrad' or tf.keras.optimizers.Adagrad(lr=学习率)</li> <li>'adadelta' or tf.keras.optimizers.Adadelta(lr=学习率)</li> <li>'adam' or tf.keras.optimizers.Adam(lr=学习率,beta_1=0.9,beta_2=0.999)</li></ul></li> <li>loss可选:
<ul><li>'mse' or tf.keras.losses.MeanSquaredError()</li> <li>'sparse_categorical_crossentropy' or tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False) 参数为是否输出经过softmax后的值</li></ul></li> <li>Metrics可选:
<ul><li>'accuracy': y_和y都是数值,如y_=[1] y=[1]</li> <li>'categorical_accuracy': y_和y都是独热码(概率分布),如y_=[0,1,0] y=[0.256,0.695,0.048]</li> <li>'parse_categorical_accuracy': y_是数值,y是独热码(概率分布)</li></ul></li></ul></li> <li>model.fit(训练集的输入特征,训练集的标签,batch_size=,epochs=,validation_data=(测试集的输入特征,测试集的标签),validation_split=从训练集划分多少比例给测试集,validation_freq=多少次epoch测试一次)</li></ul> <h3 id="八股-class"><a href="#八股-class" class="header-anchor">#</a> 八股(class)</h3> <p>.</p></div> <footer class="page-edit" style="display:none;"><!----> <!----></footer> <!----> <!----></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-44bd5a18 data-v-44bd5a18><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-44bd5a18><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-44bd5a18></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-44bd5a18></path></svg></div><div class="reco-bgm-panel" data-v-39f9e6e0><audio id="bgm" src="http://cdn.be-sunshine.cn/bgm/bg1.mp3" data-v-39f9e6e0></audio> <div class="reco-float-box" style="bottom:200px;z-index:999999;display:none;" data-v-39f9e6e0 data-v-41bcba48 data-v-39f9e6e0><img src="http://cdn.be-sunshine.cn/bgm/bg1.jpg" data-v-39f9e6e0></div> <div class="reco-bgm-box" style="left:10px;bottom:10px;z-index:999999;" data-v-39f9e6e0 data-v-41bcba48 data-v-39f9e6e0><div class="reco-bgm-cover" style="background-image:url(http://cdn.be-sunshine.cn/bgm/bg1.jpg);" data-v-39f9e6e0><div class="mini-operation" style="display:none;" data-v-39f9e6e0><i class="reco-bgm reco-bgm-pause" style="display:none;" data-v-39f9e6e0></i> <i class="reco-bgm reco-bgm-play" style="display:none;" data-v-39f9e6e0></i></div> <div class="falut-message" style="display:none;" data-v-39f9e6e0>
          播放失败
        </div></div> <div class="reco-bgm-info" data-v-39f9e6e0 data-v-41bcba48 data-v-39f9e6e0><div class="info-box" data-v-39f9e6e0><i class="reco-bgm reco-bgm-music music" data-v-39f9e6e0></i>雨后的天空</div> <div class="info-box" data-v-39f9e6e0><i class="reco-bgm reco-bgm-artist" data-v-39f9e6e0></i>glassmoon</div> <div class="reco-bgm-progress" data-v-39f9e6e0><div class="progress-bar" data-v-39f9e6e0><div class="bar" data-v-39f9e6e0></div></div></div> <div class="reco-bgm-operation" data-v-39f9e6e0><i class="reco-bgm reco-bgm-last last" data-v-39f9e6e0></i> <i class="reco-bgm reco-bgm-pause pause" style="display:none;" data-v-39f9e6e0></i> <i class="reco-bgm reco-bgm-play play" data-v-39f9e6e0></i> <i class="reco-bgm reco-bgm-next next" data-v-39f9e6e0></i> <i class="reco-bgm reco-bgm-volume1 volume" data-v-39f9e6e0></i> <i class="reco-bgm reco-bgm-mute mute" style="display:none;" data-v-39f9e6e0></i> <div class="volume-bar" data-v-39f9e6e0><div class="bar" data-v-39f9e6e0></div></div></div></div> <div class="reco-bgm-left-box" data-v-39f9e6e0 data-v-41bcba48 data-v-39f9e6e0><i class="reco-bgm reco-bgm-left" data-v-39f9e6e0></i></div></div></div></div></div>
    <script src="/public/assets/js/app.f3b4c262.js" defer></script><script src="/public/assets/js/4.fc5870ef.js" defer></script><script src="/public/assets/js/1.71bf9aac.js" defer></script><script src="/public/assets/js/18.f4ee8baa.js" defer></script>
  </body>
</html>
