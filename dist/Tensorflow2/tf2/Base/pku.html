<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>阿信 : 地平线上的一匹狼</title>
    <meta name="description" content="地平线上的一匹狼">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <link rel="stylesheet" href="http://cdn.be-sunshine.cn/winter.css">
    
    <link rel="preload" href="/dist/assets/css/0.styles.222434de.css" as="style"><link rel="preload" href="/dist/assets/js/app.6ac299af.js" as="script"><link rel="preload" href="/dist/assets/js/2.cb9dfe60.js" as="script"><link rel="preload" href="/dist/assets/js/8.af8b9b04.js" as="script"><link rel="prefetch" href="/dist/assets/js/10.c5c372b8.js"><link rel="prefetch" href="/dist/assets/js/11.115e6a38.js"><link rel="prefetch" href="/dist/assets/js/12.bf64e401.js"><link rel="prefetch" href="/dist/assets/js/13.2594d292.js"><link rel="prefetch" href="/dist/assets/js/14.309c938f.js"><link rel="prefetch" href="/dist/assets/js/15.86a4822d.js"><link rel="prefetch" href="/dist/assets/js/16.ba1f3064.js"><link rel="prefetch" href="/dist/assets/js/17.9c5ca544.js"><link rel="prefetch" href="/dist/assets/js/18.c8c21d01.js"><link rel="prefetch" href="/dist/assets/js/19.842c7ba4.js"><link rel="prefetch" href="/dist/assets/js/20.0f2b0327.js"><link rel="prefetch" href="/dist/assets/js/21.c3fcf699.js"><link rel="prefetch" href="/dist/assets/js/22.80d40e90.js"><link rel="prefetch" href="/dist/assets/js/23.19800a1d.js"><link rel="prefetch" href="/dist/assets/js/24.a7049650.js"><link rel="prefetch" href="/dist/assets/js/25.bb356cdd.js"><link rel="prefetch" href="/dist/assets/js/26.34b0d8d3.js"><link rel="prefetch" href="/dist/assets/js/27.df1205fb.js"><link rel="prefetch" href="/dist/assets/js/28.dec0bc28.js"><link rel="prefetch" href="/dist/assets/js/29.006c9ca9.js"><link rel="prefetch" href="/dist/assets/js/3.776e685f.js"><link rel="prefetch" href="/dist/assets/js/30.82868fa9.js"><link rel="prefetch" href="/dist/assets/js/31.3b7511db.js"><link rel="prefetch" href="/dist/assets/js/32.1d6c7bdd.js"><link rel="prefetch" href="/dist/assets/js/33.6725b85c.js"><link rel="prefetch" href="/dist/assets/js/34.647d775a.js"><link rel="prefetch" href="/dist/assets/js/35.8ace8300.js"><link rel="prefetch" href="/dist/assets/js/36.a4d5d016.js"><link rel="prefetch" href="/dist/assets/js/37.41f1b223.js"><link rel="prefetch" href="/dist/assets/js/38.a8796cfa.js"><link rel="prefetch" href="/dist/assets/js/39.b50b4e0a.js"><link rel="prefetch" href="/dist/assets/js/4.d9ebe5d7.js"><link rel="prefetch" href="/dist/assets/js/40.80357780.js"><link rel="prefetch" href="/dist/assets/js/41.6d239d02.js"><link rel="prefetch" href="/dist/assets/js/42.aaed3972.js"><link rel="prefetch" href="/dist/assets/js/43.b06f9408.js"><link rel="prefetch" href="/dist/assets/js/44.d9fa2388.js"><link rel="prefetch" href="/dist/assets/js/45.64a5beff.js"><link rel="prefetch" href="/dist/assets/js/46.80cebcd5.js"><link rel="prefetch" href="/dist/assets/js/47.965391f1.js"><link rel="prefetch" href="/dist/assets/js/48.6903f406.js"><link rel="prefetch" href="/dist/assets/js/49.2e17bc2d.js"><link rel="prefetch" href="/dist/assets/js/5.b7b10ecd.js"><link rel="prefetch" href="/dist/assets/js/50.fcbc16eb.js"><link rel="prefetch" href="/dist/assets/js/51.3dab0abe.js"><link rel="prefetch" href="/dist/assets/js/52.75245d2d.js"><link rel="prefetch" href="/dist/assets/js/53.dac3ab2a.js"><link rel="prefetch" href="/dist/assets/js/54.a900db4d.js"><link rel="prefetch" href="/dist/assets/js/55.feef06c3.js"><link rel="prefetch" href="/dist/assets/js/56.d70f2569.js"><link rel="prefetch" href="/dist/assets/js/6.29d3e133.js"><link rel="prefetch" href="/dist/assets/js/7.d06607d3.js"><link rel="prefetch" href="/dist/assets/js/9.1fd2b5ab.js">
    <link rel="stylesheet" href="/dist/assets/css/0.styles.222434de.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/dist/" class="home-link router-link-active"><img src="/dist/logo.png" alt="阿信 : 地平线上的一匹狼" class="logo"> <span class="site-name can-hide">阿信 : 地平线上的一匹狼</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/dist/" class="nav-link">主页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程语言" class="dropdown-title"><span class="title">编程语言</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>Java</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dist/" class="nav-link">语言高级特性</a></li><li class="dropdown-subitem"><a href="/dist/" class="nav-link">Spring技术栈</a></li><li class="dropdown-subitem"><a href="/dist/" class="nav-link">分布式</a></li></ul></li><li class="dropdown-item"><h4>Python</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dist/" class="nav-link">语言高级特性</a></li><li class="dropdown-subitem"><a href="/dist/" class="nav-link">Flask</a></li><li class="dropdown-subitem"><a href="/dist/programming_language/python/DataScience/numpy.html" class="nav-link">Numpy</a></li></ul></li><li class="dropdown-item"><h4>C++</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dist/note/G1M/Cpp/Cplus.html" class="nav-link">高级语法</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="人工智能" class="dropdown-title"><span class="title">人工智能</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/dist/Tensorflow2/tf2/Tensorflow_Keras/Keras.html" class="nav-link">Tensorflow</a></li><li class="dropdown-item"><!----> <a href="/dist/ai/ml/Modle_Represen.html" class="nav-link">机器学习</a></li><li class="dropdown-item"><!----> <a href="/dist/ai/dl/about.html" class="nav-link">神经网络</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="杂记" class="dropdown-title"><span class="title">杂记</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/dist/" class="nav-link">落書</a></li><li class="dropdown-item"><!----> <a href="/dist/zh/first/" class="nav-link">手记</a></li><li class="dropdown-item"><!----> <a href="/dist/" class="nav-link">歌记</a></li><li class="dropdown-item"><!----> <a href="/dist/note/poem/pm.html" class="nav-link">诗记</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="通用技能" class="dropdown-title"><span class="title">通用技能</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/dist/general/mysql/mysql.html" class="nav-link">MySql</a></li><li class="dropdown-item"><!----> <a href="/dist/algorithm/dp/dp.html" class="nav-link">算法</a></li><li class="dropdown-item"><!----> <a href="/dist/note/G1M/advance_ds/priority_queue.html" class="nav-link">高级数据结构</a></li><li class="dropdown-item"><!----> <a href="/dist/note/G1M/Digital_Image/Introduce.html" class="nav-link">数字图像处理</a></li><li class="dropdown-item"><!----> <a href="/dist/note/G1M/Computer_Graphics/Computer_Graphics.html" class="nav-link">计算机图形学</a></li><li class="dropdown-item"><!----> <a href="/dist/Tensorflow2/tf2/Base/note/G1M/mode/matlab.html" class="nav-link">数学建模</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="游戏/VR/AR开发" class="dropdown-title"><span class="title">游戏/VR/AR开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/dist/xr/vr/Unity.html" class="nav-link">VR</a></li><li class="dropdown-item"><!----> <a href="/dist/" class="nav-link">AR</a></li><li class="dropdown-item"><!----> <a href="/dist/" class="nav-link">GameMakerStudio</a></li></ul></div></div><div class="nav-item"><a href="http://be-sunshine.cn" target="_blank" rel="noopener noreferrer" class="nav-link external">
  hexo博客
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <a href="https://github.com/834930269/834930269.github.io/tree/master/dist" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/dist/" class="nav-link">主页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程语言" class="dropdown-title"><span class="title">编程语言</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>Java</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dist/" class="nav-link">语言高级特性</a></li><li class="dropdown-subitem"><a href="/dist/" class="nav-link">Spring技术栈</a></li><li class="dropdown-subitem"><a href="/dist/" class="nav-link">分布式</a></li></ul></li><li class="dropdown-item"><h4>Python</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dist/" class="nav-link">语言高级特性</a></li><li class="dropdown-subitem"><a href="/dist/" class="nav-link">Flask</a></li><li class="dropdown-subitem"><a href="/dist/programming_language/python/DataScience/numpy.html" class="nav-link">Numpy</a></li></ul></li><li class="dropdown-item"><h4>C++</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dist/note/G1M/Cpp/Cplus.html" class="nav-link">高级语法</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="人工智能" class="dropdown-title"><span class="title">人工智能</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/dist/Tensorflow2/tf2/Tensorflow_Keras/Keras.html" class="nav-link">Tensorflow</a></li><li class="dropdown-item"><!----> <a href="/dist/ai/ml/Modle_Represen.html" class="nav-link">机器学习</a></li><li class="dropdown-item"><!----> <a href="/dist/ai/dl/about.html" class="nav-link">神经网络</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="杂记" class="dropdown-title"><span class="title">杂记</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/dist/" class="nav-link">落書</a></li><li class="dropdown-item"><!----> <a href="/dist/zh/first/" class="nav-link">手记</a></li><li class="dropdown-item"><!----> <a href="/dist/" class="nav-link">歌记</a></li><li class="dropdown-item"><!----> <a href="/dist/note/poem/pm.html" class="nav-link">诗记</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="通用技能" class="dropdown-title"><span class="title">通用技能</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/dist/general/mysql/mysql.html" class="nav-link">MySql</a></li><li class="dropdown-item"><!----> <a href="/dist/algorithm/dp/dp.html" class="nav-link">算法</a></li><li class="dropdown-item"><!----> <a href="/dist/note/G1M/advance_ds/priority_queue.html" class="nav-link">高级数据结构</a></li><li class="dropdown-item"><!----> <a href="/dist/note/G1M/Digital_Image/Introduce.html" class="nav-link">数字图像处理</a></li><li class="dropdown-item"><!----> <a href="/dist/note/G1M/Computer_Graphics/Computer_Graphics.html" class="nav-link">计算机图形学</a></li><li class="dropdown-item"><!----> <a href="/dist/Tensorflow2/tf2/Base/note/G1M/mode/matlab.html" class="nav-link">数学建模</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="游戏/VR/AR开发" class="dropdown-title"><span class="title">游戏/VR/AR开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/dist/xr/vr/Unity.html" class="nav-link">VR</a></li><li class="dropdown-item"><!----> <a href="/dist/" class="nav-link">AR</a></li><li class="dropdown-item"><!----> <a href="/dist/" class="nav-link">GameMakerStudio</a></li></ul></div></div><div class="nav-item"><a href="http://be-sunshine.cn" target="_blank" rel="noopener noreferrer" class="nav-link external">
  hexo博客
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <a href="https://github.com/834930269/834930269.github.io/tree/master/dist" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><p>+---
title: Tensorflow2-pku笔记
sidebarDepth: 4
meta:</p> <ul><li>name: description
content: Tensorflow2笔记</li> <li>name: keywords
content: Tensorflow2</li></ul> <hr> <p></p><div class="table-of-contents"><ul><li><a href="#张量生成">张量生成</a><ul><li><a href="#数据类型">数据类型</a></li><li><a href="#创建一个tensor">创建一个Tensor</a></li><li><a href="#numpy转tensor">numpy转tensor</a></li><li><a href="#其他创建张量方法">其他创建张量方法</a></li></ul></li><li><a href="#常用函数">常用函数</a><ul><li><a href="#对于二维张量的axis">对于二维张量的axis</a></li><li><a href="#举例">举例</a></li><li><a href="#tf-variable">tf.Variable</a></li><li><a href="#数学运算">数学运算</a></li><li><a href="#data">data</a></li><li><a href="#tf-gradienttape">tf.GradientTape</a></li><li><a href="#enumerate">enumerate</a></li><li><a href="#tf-one-hot">tf.one_hot</a></li><li><a href="#tf-nn-softmax">tf.nn.softmax</a></li><li><a href="#assign-sub">assign_sub</a></li><li><a href="#tf-argmax">tf.argmax</a></li><li><a href="#鸢尾花">鸢尾花</a></li><li><a href="#神经网络实现鸢尾花分类">神经网络实现鸢尾花分类</a></li></ul></li><li><a href="#优化器">优化器</a><ul><li><a href="#tf-where">tf.where</a></li><li><a href="#np-random-randomstate-rand">np.random.RandomState.rand()</a></li><li><a href="#np-vstack">np.vstack()</a></li><li><a href="#生成网格坐标点">生成网格坐标点</a></li><li><a href="#复杂学习率">复杂学习率</a></li><li><a href="#激活函数">激活函数</a></li><li><a href="#损失函数">损失函数</a></li><li><a href="#缓解过拟合">缓解过拟合</a></li></ul></li><li><a href="#神经网络八股-使用keras">神经网络八股(使用keras)</a><ul><li><a href="#六步法">六步法</a></li><li><a href="#sequential-网络结构">Sequential([网络结构])</a></li><li><a href="#八股-class">八股(class)</a></li></ul></li></ul></div><p></p> <h1 id="tensorflow2-pku"><a href="#tensorflow2-pku" class="header-anchor">#</a> Tensorflow2-pku</h1> <h2 id="张量生成"><a href="#张量生成" class="header-anchor">#</a> 张量生成</h2> <blockquote><p>即多维数组,一阶称为向量,二阶称为矩阵,n阶统称为张量</p></blockquote> <h3 id="数据类型"><a href="#数据类型" class="header-anchor">#</a> 数据类型</h3> <blockquote><p>tf.int,tf.float</p> <blockquote><p>tf.int32,tf.float32,tf.float64
tf.bool
tf.constant([True,False])
tf.string
tf.constant(&quot;Hello,world!&quot;)</p></blockquote></blockquote> <h3 id="创建一个tensor"><a href="#创建一个tensor" class="header-anchor">#</a> 创建一个Tensor</h3> <blockquote><p>tf.constant(张量内容,dtype=数据类型(可选))</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment"># 结果</span>
<span class="token triple-quoted-string string">'''
tf.Tensor([1 5], shape=(2,), dtype=int64)
&lt;dtype: 'int64'&gt;
(2,)
'''</span>
</code></pre></div><h3 id="numpy转tensor"><a href="#numpy转tensor" class="header-anchor">#</a> numpy转tensor</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
a <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>convert_to_tensor<span class="token punctuation">(</span>a<span class="token punctuation">,</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span>
</code></pre></div><h3 id="其他创建张量方法"><a href="#其他创建张量方法" class="header-anchor">#</a> 其他创建张量方法</h3> <div class="language-python extra-class"><pre class="language-python"><code>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>维度<span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>维度<span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>fill<span class="token punctuation">(</span>维度<span class="token punctuation">,</span>指定值<span class="token punctuation">)</span>

a<span class="token operator">=</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>fill<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>维度<span class="token punctuation">,</span>mean<span class="token operator">=</span>均值<span class="token punctuation">,</span>stddev<span class="token operator">=</span>标准差<span class="token punctuation">)</span>
<span class="token comment"># 默认均值0,标准差1,正态分布随机数</span>

<span class="token comment"># 截断式正态分布随机数,数据集中在均值附近</span>
tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span>维度<span class="token punctuation">,</span>mean<span class="token operator">=</span>均值<span class="token punctuation">,</span>stddev<span class="token operator">=</span>标准差<span class="token punctuation">)</span>

d <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span>

e <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''
tf.Tensor(
[[ 1.3927269   0.06218731]
 [-0.8482692  -0.81205285]], shape=(2, 2), dtype=float32)
tf.Tensor(
[[ 1.7386221   0.0458321 ]
 [ 0.51848936 -0.32362974]], shape=(2, 2), dtype=float32)

'''</span>


<span class="token comment"># 生成均匀分布随机数[min,max)</span>
tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span>维度<span class="token punctuation">,</span>minval<span class="token operator">=</span>最小值<span class="token punctuation">,</span>maxval<span class="token operator">=</span>最大值<span class="token punctuation">)</span>
f <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>minval<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>maxval<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token punctuation">)</span>
</code></pre></div><h2 id="常用函数"><a href="#常用函数" class="header-anchor">#</a> 常用函数</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 强制tensor转换为该数据类型</span>
tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>张量名<span class="token punctuation">,</span>dtype<span class="token operator">=</span>数据类型<span class="token punctuation">)</span>

<span class="token comment"># 计算张量维度上元素的最小值</span>
tf<span class="token punctuation">.</span>reduce_min<span class="token punctuation">(</span>张量名<span class="token punctuation">)</span>

<span class="token comment"># 计算张量维度上元素的最大值</span>
tf<span class="token punctuation">.</span>reduce_max<span class="token punctuation">(</span>张量名<span class="token punctuation">)</span>

x1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float64<span class="token punctuation">)</span>
x2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x1<span class="token punctuation">,</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>

</code></pre></div><h3 id="对于二维张量的axis"><a href="#对于二维张量的axis" class="header-anchor">#</a> 对于二维张量的axis</h3> <blockquote><p>axis指定是控制行维度还是列为度</p> <blockquote><p>axis=0代表跨行(逐列),axis=1代表跨列(逐行)
不指定axis,则所有元素参与计算</p></blockquote></blockquote> <h3 id="举例"><a href="#举例" class="header-anchor">#</a> 举例</h3> <blockquote><p>求平均值</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>张量名<span class="token punctuation">,</span>axis<span class="token operator">=</span>操作轴<span class="token punctuation">)</span>
</code></pre></div><blockquote><p>求和</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>张量名<span class="token punctuation">,</span>axis<span class="token operator">=</span>操作轴<span class="token punctuation">)</span>
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code>x <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>x<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="tf-variable"><a href="#tf-variable" class="header-anchor">#</a> tf.Variable</h3> <blockquote><p>tf.Varliable()<code>将变量标记为&quot;可训练&quot;</code>,被标记的变量会在反向传播中记录梯度信息,神经网络训练中,常用该函数标记待训练参数</p></blockquote> <h3 id="数学运算"><a href="#数学运算" class="header-anchor">#</a> 数学运算</h3> <blockquote><p>四则运算</p> <blockquote><p>tf.add,tf.subtract,tf.multiply,tf.divide</p> <blockquote><p>参数(张量1,张量2)</p></blockquote></blockquote></blockquote> <blockquote><p>平方,次方与开方</p> <blockquote><p>tf.square,tf.pow,tf.sqrt</p></blockquote></blockquote> <blockquote><p>矩阵乘</p> <blockquote><p>tf.matmul</p></blockquote></blockquote> <h3 id="data"><a href="#data" class="header-anchor">#</a> data</h3> <blockquote><p>神经网络训练时,是将标签和数据配对后再进行计算的</p></blockquote> <blockquote><p>tf.data.Dataset.from_tensor_slices</p></blockquote> <blockquote><p>切分传入张量的第一维度,生成输入特征/标签对,构建数据集 data = tf.data.Dataset.from_tensor_slices((输入特征,标签))</p></blockquote> <blockquote><p>numpy和tensor格式都可以用该语句读入数据</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code>features <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
labels <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>

<span class="token keyword">for</span> elem <span class="token keyword">in</span> dataset<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>elem<span class="token punctuation">)</span>

<span class="token comment"># 输出</span>
<span class="token triple-quoted-string string">'''
&lt;TensorSliceDataset shapes: ((), ()), types: (tf.int32, tf.int32)&gt;
(&lt;tf.Tensor: id=997, shape=(), dtype=int32, numpy=12&gt;, &lt;tf.Tensor: id=998, shape=(), dtype=int32, numpy=0&gt;)
(&lt;tf.Tensor: id=999, shape=(), dtype=int32, numpy=23&gt;, &lt;tf.Tensor: id=1000, shape=(), dtype=int32, numpy=1&gt;)
(&lt;tf.Tensor: id=1001, shape=(), dtype=int32, numpy=10&gt;, &lt;tf.Tensor: id=1002, shape=(), dtype=int32, numpy=1&gt;)
(&lt;tf.Tensor: id=1003, shape=(), dtype=int32, numpy=17&gt;, &lt;tf.Tensor: id=1004, shape=(), dtype=int32, numpy=0&gt;)

'''</span>
</code></pre></div><h3 id="tf-gradienttape"><a href="#tf-gradienttape" class="header-anchor">#</a> tf.GradientTape</h3> <blockquote><p>with 结构记录计算过程，gradient求出张量的梯度
with tf.GradientTape() as tape:
若干个计算过程
grad = tape.gradient(函数,对谁求导)</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientType<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>
	w <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">3.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	loss <span class="token operator">=</span> tf<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment"># 损失函数是w^2,对w求导</span>
grad <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss<span class="token punctuation">,</span>w<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>grad<span class="token punctuation">)</span>

<span class="token comment"># 运行结果: tf.Tensor(6.0,shape=(),dtype=float32)</span>
</code></pre></div><h3 id="enumerate"><a href="#enumerate" class="header-anchor">#</a> enumerate</h3> <blockquote><p>enumerate是python的内建函数,他可遍历每个元素(如列表,元祖,或字符串),结合为: 索引,元素,常在for循环中使用。
enumerate(列表名)</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code>seq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'one'</span><span class="token punctuation">,</span><span class="token string">'two'</span><span class="token punctuation">,</span><span class="token string">'three'</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span>elem <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>seq<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>elem<span class="token punctuation">)</span>
</code></pre></div><h3 id="tf-one-hot"><a href="#tf-one-hot" class="header-anchor">#</a> tf.one_hot</h3> <blockquote><p>独热编码: 在分类问题中,常用独热码作为标签.
tf.one_hot(待转换数据,depth=几分类)</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code>classes<span class="token operator">=</span><span class="token number">3</span>
labels <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
output<span class="token operator">=</span>tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>labels<span class="token punctuation">,</span>depth<span class="token operator">=</span>classes<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''
tf.Tensor(
[[0. 1. 0.]
 [1. 0. 0.]
 [0. 0. 1.]], shape=(3, 3), dtype=float32)
'''</span>
</code></pre></div><h3 id="tf-nn-softmax"><a href="#tf-nn-softmax" class="header-anchor">#</a> tf.nn.softmax</h3> <p><img src="http://cdn.be-sunshine.cn/pku_softmax.png" alt=""></p> <div class="language-python extra-class"><pre class="language-python"><code>y <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.01</span><span class="token punctuation">,</span><span class="token number">2.01</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.66</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_pro <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;After softmax,y_pro is: &quot;</span><span class="token punctuation">,</span>y_pro<span class="token punctuation">)</span>

<span class="token comment"># 输出</span>
<span class="token triple-quoted-string string">'''
After softmax,y_pro is:  tf.Tensor([0.25598174 0.69583046 0.0481878 ], shape=(3,), dtype=float32)
'''</span>
</code></pre></div><h3 id="assign-sub"><a href="#assign-sub" class="header-anchor">#</a> assign_sub</h3> <blockquote><p>赋值操作,更新参数的值并返回
调用assign_sub前,先用tf.Variable定义变量w为可训练(可自更新)
w.assign_sub(w要自减的内容)</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code>w <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
w<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span>
</code></pre></div><h3 id="tf-argmax"><a href="#tf-argmax" class="header-anchor">#</a> tf.argmax</h3> <blockquote><p>返回张量沿制定维度最大值的索引 tf.argmax(张量名,axis=操作轴)</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>test<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 返回每一列最大值的索引</span>
</code></pre></div><h3 id="鸢尾花"><a href="#鸢尾花" class="header-anchor">#</a> 鸢尾花</h3> <h4 id="读入数据"><a href="#读入数据" class="header-anchor">#</a> 读入数据</h4> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> pandas <span class="token keyword">import</span> DataFrame
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

x_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data <span class="token comment"># 读取所有数据</span>
y_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>target <span class="token comment"># 所有标签</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;x_data from datasets: \n&quot;</span><span class="token punctuation">,</span>x_data<span class="token punctuation">)</span>

<span class="token comment"># 使用DataFrame为每一列增加中文注释</span>
x_data <span class="token operator">=</span> DataFrame<span class="token punctuation">(</span>x_data<span class="token punctuation">,</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;花萼长度&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;花萼宽度&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;花瓣长度&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;花瓣宽度&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
pd<span class="token punctuation">.</span>set_option<span class="token punctuation">(</span><span class="token string">'display.unicode.east_asian_width'</span><span class="token punctuation">,</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment"># 设置列名对齐</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x_data add index:\n'</span><span class="token punctuation">,</span>x_data<span class="token punctuation">)</span>

x_data<span class="token punctuation">[</span><span class="token string">'类别'</span><span class="token punctuation">]</span> <span class="token operator">=</span> y_data <span class="token comment">#添加一列</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x_data add a column: \n'</span><span class="token punctuation">,</span>x_data<span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code># 输出
x_data add index:
      花萼长度  花萼宽度  花瓣长度  花瓣宽度
0         5.1       3.5       1.4       0.2
1         4.9       3.0       1.4       0.2
2         4.7       3.2       1.3       0.2
3         4.6       3.1       1.5       0.2
4         5.0       3.6       1.4       0.2
					...
21        5.1       3.7       1.5       0.4
146       6.3       2.5       5.0       1.9
147       6.5       3.0       5.2       2.0
148       6.2       3.4       5.4       2.3
149       5.9       3.0       5.1       1.8

[150 rows x 4 columns]
x_data add a column: 
      花萼长度  花萼宽度  花瓣长度  花瓣宽度  类别
0         5.1       3.5       1.4       0.2     0
1         4.9       3.0       1.4       0.2     0
2         4.7       3.2       1.3       0.2     0
3         4.6       3.1       1.5       0.2     0
4         5.0       3.6       1.4       0.2     0
5         5.4       3.9       1.7       0.4     0
6         4.6       3.4       1.4       0.3     0
7         5.0       3.4       1.5       0.2     0
..        ...       ...       ...       ...   ...
142       5.8       2.7       5.1       1.9     2
143       6.8       3.2       5.9       2.3     2
144       6.7       3.3       5.7       2.5     2
145       6.7       3.0       5.2       2.3     2
146       6.3       2.5       5.0       1.9     2
147       6.5       3.0       5.2       2.0     2
148       6.2       3.4       5.4       2.3     2
149       5.9       3.0       5.1       1.8     2

[150 rows x 5 columns]
</code></pre></div><h3 id="神经网络实现鸢尾花分类"><a href="#神经网络实现鸢尾花分类" class="header-anchor">#</a> 神经网络实现鸢尾花分类</h3> <ul><li>准备数据
<ul><li>数据集读入</li> <li>数据集乱序</li> <li>生成训练集和测试集</li> <li>配成(输入特征,标签)对,每次读入一小撮(batch)</li></ul></li> <li>搭建网络
<ul><li>定义神经网络中所有可训练参数</li></ul></li> <li>参数优化
<ul><li>嵌套循环迭代,with结构更新参数,显示当前loss</li></ul></li> <li>测试效果
<ul><li>计算当前参数前向传播后的准确率,显示当前acc</li></ul></li> <li>acc/loss可视化</li></ul> <h4 id="代码"><a href="#代码" class="header-anchor">#</a> 代码</h4> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> pandas <span class="token keyword">import</span> DataFrame
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np 
<span class="token keyword">import</span> os
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">&quot;-1&quot;</span>    
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> matplotlib

x_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data <span class="token comment"># 读取所有数据</span>
y_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>target <span class="token comment"># 所有标签</span>

<span class="token comment"># 数据集乱序</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>y_data<span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>set_seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>

<span class="token comment"># 数据集分出永不相见的训练集和测试集</span>
x_train <span class="token operator">=</span> x_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">]</span>
y_train <span class="token operator">=</span> y_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">]</span>
x_test <span class="token operator">=</span> x_data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
y_test <span class="token operator">=</span> y_data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
<span class="token comment"># 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错</span>
x_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
x_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

<span class="token comment"># 配对打包,配置batch，以batch为单位输入神经网络</span>
train_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
test_db <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>

<span class="token comment"># 定义可训练参数</span>
w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
b1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#定义超参数</span>
lr <span class="token operator">=</span> <span class="token number">0.1</span>
train_loss_results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
test_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
epoch <span class="token operator">=</span> <span class="token number">500</span>
loss_all <span class="token operator">=</span> <span class="token number">0</span>

<span class="token comment"># 嵌套循环迭代,with结构更新参数,显示当前loss</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#数据集级别迭代</span>
    <span class="token keyword">for</span> step<span class="token punctuation">,</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_db<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#batch级别迭代</span>
        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span> <span class="token comment">#记录梯度信息</span>
            <span class="token comment">#面向传播过程计算y</span>
            y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>w1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
            y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token comment">#softmax不是损失函数,只是变成概率形式</span>
            y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span>depth<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
            loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>y_ <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 均方误差损失函数</span>
            loss_all <span class="token operator">+=</span> loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment">#计算总loss</span>
        grads <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss<span class="token punctuation">,</span><span class="token punctuation">[</span>w1<span class="token punctuation">,</span>b1<span class="token punctuation">]</span><span class="token punctuation">)</span>
        w1<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span>lr<span class="token operator">*</span>grads<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 参数自更新</span>
        b1<span class="token punctuation">.</span>assign_sub<span class="token punctuation">(</span>lr<span class="token operator">*</span>grads<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Epoch {},loss: {}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss_all<span class="token operator">/</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 因为每个epoch会有四个step,所以求这四个stpe的平均值</span>
    train_loss_results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss_all <span class="token operator">/</span> <span class="token number">4</span><span class="token punctuation">)</span>
    loss_all <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment">#重新初始化</span>
    
    <span class="token comment">#测试</span>
    total_correct<span class="token punctuation">,</span>total_number <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    <span class="token keyword">for</span> x_test<span class="token punctuation">,</span>y_test <span class="token keyword">in</span> test_db<span class="token punctuation">:</span>
        <span class="token comment">#使用更新后的参数</span>
        y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>w1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
        y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 返回y中最大值的索引,即预测的分类</span>
        pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>pred<span class="token punctuation">,</span>dtype<span class="token operator">=</span>y_test<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
        correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>pred<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
        correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>correct<span class="token punctuation">)</span> <span class="token comment">#即正确的个数</span>
        total_correct <span class="token operator">+=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>correct<span class="token punctuation">)</span>
        total_number <span class="token operator">+=</span> x_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    acc <span class="token operator">=</span> total_correct <span class="token operator">/</span> total_number
    test_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'test_acc: '</span><span class="token punctuation">,</span>acc<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'---------------------------------------'</span><span class="token punctuation">)</span>
    
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token comment"># loss 曲线</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Loss Function Curve'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_loss_results<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'$Loss$'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#画出曲线图标</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>部分输出:
Epoch 4,loss: 0.19942264631390572
test_acc:  0.16666666666666666
---------------------------------------
Epoch 5,loss: 0.18873637914657593
test_acc:  0.5
---------------------------------------
Epoch 6,loss: 0.17851300165057182
test_acc:  0.5333333333333333
---------------------------------------
Epoch 7,loss: 0.16922876238822937
test_acc:  0.5333333333333333
---------------------------------------
Epoch 499,loss: 0.03230027528479695
test_acc:  1.0
---------------------------------------
</code></pre></div><h2 id="优化器"><a href="#优化器" class="header-anchor">#</a> 优化器</h2> <h3 id="tf-where"><a href="#tf-where" class="header-anchor">#</a> tf.where</h3> <blockquote><p>条件语句真返回A,假返回B</p> <blockquote><p>tf.where(条件语句,A,B)</p></blockquote></blockquote> <div class="language-python extra-class"><pre class="language-python"><code>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> tf<span class="token punctuation">.</span>where<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>greater<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span> <span class="token comment"># 若a&gt;b,为真</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;c:&quot;</span><span class="token punctuation">,</span>c<span class="token punctuation">)</span>
</code></pre></div><h3 id="np-random-randomstate-rand"><a href="#np-random-randomstate-rand" class="header-anchor">#</a> np.random.RandomState.rand()</h3> <blockquote><p>返回一个[0,1)之间的随机数
np.random.RandomState.rand(维度) # 维度为空则返回标量</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
rdm <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>RandomState<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment"># 返回维度为2行3列随机数矩阵</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;a:&quot;</span><span class="token punctuation">,</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;b:&quot;</span><span class="token punctuation">,</span>b<span class="token punctuation">)</span>
</code></pre></div><h3 id="np-vstack"><a href="#np-vstack" class="header-anchor">#</a> np.vstack()</h3> <blockquote><p>将两个数组按垂直方向叠加
np.vstack(数组1,数组2)</p></blockquote> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;c:\n&quot;</span><span class="token punctuation">,</span>c<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''
c:
[[1 2 3]
[4 5 6]]
'''</span>
</code></pre></div><h3 id="生成网格坐标点"><a href="#生成网格坐标点" class="header-anchor">#</a> 生成网格坐标点</h3> <blockquote><p>np.mgrid[]</p> <blockquote><p>np.mgrid[起始值:结束值:步长,起始值:结束值:步长,...]</p> <blockquote><p>[A,B)
也可以a🅱️cj
[a,b)区间内取c个点</p></blockquote></blockquote></blockquote> <blockquote><p>x.ravel()</p> <blockquote><p>将x变成一维数组</p></blockquote></blockquote> <blockquote><p>np.c_[] 使返回的间隔数值点配对</p> <blockquote><p>np.c_[数组1,数组2,...]</p></blockquote></blockquote> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
x<span class="token punctuation">,</span>y <span class="token operator">=</span> np<span class="token punctuation">.</span>mgrid<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token number">0.5</span><span class="token punctuation">]</span>
grid <span class="token operator">=</span> np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>x<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>y<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;x:&quot;</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;y:&quot;</span><span class="token punctuation">,</span>y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;grid:\n&quot;</span><span class="token punctuation">,</span>grid<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''
x: [[1. 1. 1. 1.]
 [2. 2. 2. 2.]]
y: [[2.  2.5 3.  3.5]
 [2.  2.5 3.  3.5]]
grid:
 [[1.  2. ]
 [1.  2.5]
 [1.  3. ]
 [1.  3.5]
 [2.  2. ]
 [2.  2.5]
 [2.  3. ]
 [2.  3.5]]

'''</span>
</code></pre></div><h3 id="复杂学习率"><a href="#复杂学习率" class="header-anchor">#</a> 复杂学习率</h3> <h4 id="指数衰减学习率"><a href="#指数衰减学习率" class="header-anchor">#</a> 指数衰减学习率</h4> <blockquote><p>可以先用较大的学习率,快速得到较优解,然后逐步减小学习率,使模型在训练后期稳定
指数衰减学习率 = 初始学习率*学习率衰减率^(当前论述/多少轮衰减一次)</p></blockquote> <h3 id="激活函数"><a href="#激活函数" class="header-anchor">#</a> 激活函数</h3> <blockquote><p>用于使模型变成非线性</p></blockquote> <h4 id="sigmoid"><a href="#sigmoid" class="header-anchor">#</a> sigmoid</h4> <blockquote><p>tf.nn.sigmoid(x)</p></blockquote> <ul><li>易造成梯度消失</li> <li>输出非0均值,收敛慢</li> <li>幂运算复杂,训练时间长</li></ul> <h4 id="relu"><a href="#relu" class="header-anchor">#</a> relu</h4> <blockquote><p>tf.nn.relu(x)</p></blockquote> <blockquote><p>优点</p></blockquote> <ul><li>解决了梯度消失问题(在正区间)</li> <li>只需判断输入是否大于0,计算速度块</li> <li>收敛速度远快于sigmoid和tanh</li></ul> <blockquote><p>缺点</p></blockquote> <ul><li>输出非0均值,收敛慢</li> <li>缺失Relu问题,某些神经元网络可能永远不会被激活,导致的相应参数永远不会被更新</li></ul> <h4 id="leaky-relu"><a href="#leaky-relu" class="header-anchor">#</a> Leaky Relu</h4> <blockquote><p>tf.nn.leaky_relu(x)
理论上优于relu,但是没有完全证明leakyrelu总是优于relu</p></blockquote> <h3 id="损失函数"><a href="#损失函数" class="header-anchor">#</a> 损失函数</h3> <blockquote><p>预测值(y)与已知答案(y_)的差距</p> <blockquote><p>NN优化目标: loss最小</p></blockquote></blockquote> <blockquote><p>主流loss</p></blockquote> <ul><li>mse 均方误差</li> <li>自定义</li> <li>ce(cross entropy) 交叉熵</li></ul> <h4 id="均方误差mse"><a href="#均方误差mse" class="header-anchor">#</a> 均方误差mse</h4> <blockquote><p>loss_mse = tf.reduce_mean(tf.square(y_-y))</p></blockquote> <h4 id="自定义损失函数"><a href="#自定义损失函数" class="header-anchor">#</a> 自定义损失函数</h4> <blockquote><p>这点建议自己去看下，pku的tensorflow22.4节</p></blockquote> <p>       关键为了解决: 预测多了,损失成本.预测少了,损失利润.而我们的均方误差损失函数默认的是无论预测多还是少均是损失&quot;成本&quot;</p> <h4 id="交叉熵损失函数ce"><a href="#交叉熵损失函数ce" class="header-anchor">#</a> 交叉熵损失函数ce</h4> <blockquote><p>表示两个概率分布之间的距离</p> <blockquote><p>常用在one-hot一类的概率表示法中</p></blockquote></blockquote> <h3 id="缓解过拟合"><a href="#缓解过拟合" class="header-anchor">#</a> 缓解过拟合</h3> <blockquote><p>欠拟合的解决方法</p></blockquote> <ul><li>增加输入特征项</li> <li>增加网络参数</li> <li>减少正则化参数</li></ul> <blockquote><p>过拟合的解决方法</p></blockquote> <ul><li>数据清洗</li> <li>增大训练集</li> <li>采用正则化</li> <li>增大正则化参数</li></ul> <h4 id="正则化缓解过拟合"><a href="#正则化缓解过拟合" class="header-anchor">#</a> 正则化缓解过拟合</h4> <p>.</p> <h4 id="优化器-2"><a href="#优化器-2" class="header-anchor">#</a> 优化器</h4> <p>.</p> <h2 id="神经网络八股-使用keras"><a href="#神经网络八股-使用keras" class="header-anchor">#</a> 神经网络八股(使用keras)</h2> <h3 id="六步法"><a href="#六步法" class="header-anchor">#</a> 六步法</h3> <ul><li>import</li> <li>train,test数据集</li> <li>model = tf.keras.models.Sequential</li> <li>model.compile</li> <li>model.fit</li> <li>model.summary</li></ul> <h3 id="sequential-网络结构"><a href="#sequential-网络结构" class="header-anchor">#</a> Sequential([网络结构])</h3> <blockquote><p>举例:</p></blockquote> <ul><li>拉直层: tf.keras.layers.Fatten() #将Nd的数据拉直成1D</li> <li>全连接层: tf.keras.layers.Dense(神经元个数,activation=&quot;激活函数&quot;,kernel_regularizer=哪种正则化)
<ul><li>activation(字符串给出)可选: relu、softmax、sigmoid、tanh</li> <li>kernel_regularizer可选: tf.keras.regularizers.l1()、tf.keras.regularizers.l2()</li></ul></li> <li>卷积层: tf.keras.layers.Conv2D(filters=卷积核个数,kernel_size=卷几何尺寸,strides=卷及步长,padding=&quot;valid&quot; or &quot;same&quot;)</li> <li>LSTM层: tf.keras.layers.LSTM()</li> <li>model.compile(optimizer=优化器,loss=损失函数,metrics=[&quot;评测指标&quot;])
<ul><li>OPTIMIZER可选:
<ul><li>'sgd' or tf.keras.optimizers.SGD(lr=学习率,momentum=栋梁参数)</li> <li>'adagrad' or tf.keras.optimizers.Adagrad(lr=学习率)</li> <li>'adadelta' or tf.keras.optimizers.Adadelta(lr=学习率)</li> <li>'adam' or tf.keras.optimizers.Adam(lr=学习率,beta_1=0.9,beta_2=0.999)</li></ul></li> <li>loss可选:
<ul><li>'mse' or tf.keras.losses.MeanSquaredError()</li> <li>'sparse_categorical_crossentropy' or tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False) 参数为是否输出经过softmax后的值</li></ul></li> <li>Metrics可选:
<ul><li>'accuracy': y_和y都是数值,如y_=[1] y=[1]</li> <li>'categorical_accuracy': y_和y都是独热码(概率分布),如y_=[0,1,0] y=[0.256,0.695,0.048]</li> <li>'parse_categorical_accuracy': y_是数值,y是独热码(概率分布)</li></ul></li></ul></li> <li>model.fit(训练集的输入特征,训练集的标签,batch_size=,epochs=,validation_data=(测试集的输入特征,测试集的标签),validation_split=从训练集划分多少比例给测试集,validation_freq=多少次epoch测试一次)</li></ul> <h3 id="八股-class"><a href="#八股-class" class="header-anchor">#</a> 八股(class)</h3> <p>.</p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/834930269/834930269.github.io/tree/master/dist/edit/master/docs/Tensorflow2/tf2/Base/pku.md" target="_blank" rel="noopener noreferrer">Edit this page</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/dist/assets/js/app.6ac299af.js" defer></script><script src="/dist/assets/js/2.cb9dfe60.js" defer></script><script src="/dist/assets/js/8.af8b9b04.js" defer></script>
  </body>
</html>
